{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5c0d2440b3e4995a794ded565213150",
        "deepnote_cell_type": "markdown",
        "id": "_Mql1uRoI5v5"
      },
      "source": [
        "<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
        "deepnote_cell_type": "markdown",
        "id": "FAPGIlEAI5v8"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
        "deepnote_cell_type": "markdown",
        "id": "8NozgbkZI5v9"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
        "\n",
        "- Nombre de alumno 1:\n",
        "- Nombre de alumno 2:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/...../)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
        "deepnote_cell_type": "markdown",
        "id": "vHU9DI6wI5v9"
      },
      "source": [
        "### Temas a tratar\n",
        "\n",
        "- Predicci칩n de demanda usando `xgboost`\n",
        "- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n",
        "- Uso de pipelines.\n",
        "\n",
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C칩digo que no se pueda ejecutar, no ser치 revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Optimizar modelos usando `optuna`\n",
        "- Recurrir a t칠cnicas de *prunning*\n",
        "- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n",
        "- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
        "deepnote_cell_type": "markdown",
        "id": "U_-sNOuOI5v9"
      },
      "source": [
        "# Importamos librerias 칰tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "51afe4d2df42442b9e5402ffece60ead",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4957,
        "execution_start": 1699544354044,
        "id": "ekHbM85NI5v9",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "#!pip install -qq xgboost optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hJXpLCSspz"
      },
      "source": [
        "# El emprendimiento de Fiu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44d227389a734ac59189c5e0005bc68a",
        "deepnote_cell_type": "markdown",
        "id": "b0bDalAOI5v-"
      },
      "source": [
        "Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Al ver el gran potencial y talento que usted ha demostrado en el campo de la ciencia de datos, Fiu lo contrata como data scientist para que forme parte de su nuevo emprendimiento.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
        "\n",
        "Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n",
        "\n",
        "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 92,
        "execution_start": 1699544359006,
        "id": "QvMPOqHuI5v-",
        "outputId": "659e7a12-d74d-45d6-d3c2-33a6cd338585",
        "source_hash": null
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>pop</th>\n",
              "      <th>shop</th>\n",
              "      <th>brand</th>\n",
              "      <th>container</th>\n",
              "      <th>capacity</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.96</td>\n",
              "      <td>13280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.86</td>\n",
              "      <td>6727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.87</td>\n",
              "      <td>9848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>20050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.39</td>\n",
              "      <td>25696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id      date    city       lat      long     pop    shop        brand  \\\n",
              "0   0  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "1   1  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "2   2  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
              "3   3  31/01/12  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "4   4  31/01/12  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
              "\n",
              "  container capacity  price  quantity  \n",
              "0     glass    500ml   0.96     13280  \n",
              "1   plastic    1.5lt   2.86      6727  \n",
              "2       can    330ml   0.87      9848  \n",
              "3     glass    500ml   1.00     20050  \n",
              "4       can    330ml   0.39     25696  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv('sales.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id           7456\n",
              "date           84\n",
              "city            5\n",
              "lat             6\n",
              "long            6\n",
              "pop            35\n",
              "shop            6\n",
              "brand           5\n",
              "container       3\n",
              "capacity        3\n",
              "price         402\n",
              "quantity     6906\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cantidad de valores 칰nicos por columna\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
        "deepnote_cell_type": "markdown",
        "id": "pk4ru76pI5v_"
      },
      "source": [
        "## 1 Generando un Baseline (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
        "</p>\n",
        "\n",
        "Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n",
        "\n",
        "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad. [0.5 puntos]\n",
        "2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas. [1 punto]\n",
        "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas. `Nota:` Utilice el m칠todo `.set_output(transform='pandas')` para obtener un DataFrame como salida del `ColumnTransformer` [1 punto]\n",
        "4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios. [0.5 punto]\n",
        "5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio? [0.5 puntos]\n",
        "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`? [1 punto]\n",
        "7. Guarde ambos modelos en un archivo .pkl (uno cada uno) [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cell_id": "1482c992d9494e5582b23dbd3431dbfd",
        "deepnote_cell_type": "code",
        "id": "sfnN7HubI5v_"
      },
      "outputs": [],
      "source": [
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Separaci칩n de conjuntos**\n",
        "\n",
        "Dado que la variable que queremos predecir es `quantity`, primero separaremos el dataset entre *datos* y *labels*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(columns = ['id', 'quantity'])\n",
        "y = df['quantity']\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=30)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.222, random_state=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Implementaci칩n `FunctionTransformer`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def date_extractor(df):\n",
        "    '''\n",
        "    Extrae el d칤a, mes y a침o de una la columna 'date'\n",
        "\n",
        "    Args\n",
        "        df: DataFrame\n",
        "\n",
        "    Returns\n",
        "        transdformed_df: DataFrame con las columnas 'day', 'month' y 'year' y eliminada 'date'\n",
        "    '''\n",
        "    # Creaci칩n de las columnas separadas\n",
        "    transformed_df = df.copy()\n",
        "    transformed_df['date'] = pd.to_datetime(transformed_df['date'], format='%d/%m/%y', dayfirst = True)\n",
        "    transformed_df['day'] = transformed_df['date'].dt.day.astype('category')\n",
        "    transformed_df['month'] = transformed_df['date'].dt.month.astype('category')\n",
        "    transformed_df['year'] = transformed_df['date'].dt.year.astype('category')\n",
        "    transformed_df = transformed_df.drop(columns = 'date')\n",
        "\n",
        "    # Guardado\n",
        "\n",
        "    return transformed_df\n",
        "\n",
        "# Creamos el transformer para aplicar esta nueva funci칩n\n",
        "date_transformer = FunctionTransformer(date_extractor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Implementaci칩n `ColumnTransformer`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>pop</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7456.000000</td>\n",
              "      <td>7456.000000</td>\n",
              "      <td>7456.000000</td>\n",
              "      <td>7456.000000</td>\n",
              "      <td>7456.000000</td>\n",
              "      <td>7456.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3784.926770</td>\n",
              "      <td>38.300616</td>\n",
              "      <td>23.270170</td>\n",
              "      <td>355042.733637</td>\n",
              "      <td>1.197193</td>\n",
              "      <td>29408.428380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2185.822361</td>\n",
              "      <td>1.650030</td>\n",
              "      <td>1.086592</td>\n",
              "      <td>232336.703020</td>\n",
              "      <td>0.818175</td>\n",
              "      <td>17652.985675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.327870</td>\n",
              "      <td>21.734440</td>\n",
              "      <td>134219.000000</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>2953.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1889.750000</td>\n",
              "      <td>37.962450</td>\n",
              "      <td>22.417610</td>\n",
              "      <td>141732.000000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>16572.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3783.500000</td>\n",
              "      <td>38.244440</td>\n",
              "      <td>22.930860</td>\n",
              "      <td>257501.500000</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>25294.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5682.250000</td>\n",
              "      <td>39.636890</td>\n",
              "      <td>23.716220</td>\n",
              "      <td>665102.000000</td>\n",
              "      <td>1.510000</td>\n",
              "      <td>37699.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7559.000000</td>\n",
              "      <td>40.643610</td>\n",
              "      <td>25.143410</td>\n",
              "      <td>672130.000000</td>\n",
              "      <td>4.790000</td>\n",
              "      <td>145287.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id          lat         long            pop        price  \\\n",
              "count  7456.000000  7456.000000  7456.000000    7456.000000  7456.000000   \n",
              "mean   3784.926770    38.300616    23.270170  355042.733637     1.197193   \n",
              "std    2185.822361     1.650030     1.086592  232336.703020     0.818175   \n",
              "min       0.000000    35.327870    21.734440  134219.000000     0.110000   \n",
              "25%    1889.750000    37.962450    22.417610  141732.000000     0.620000   \n",
              "50%    3783.500000    38.244440    22.930860  257501.500000     0.930000   \n",
              "75%    5682.250000    39.636890    23.716220  665102.000000     1.510000   \n",
              "max    7559.000000    40.643610    25.143410  672130.000000     4.790000   \n",
              "\n",
              "            quantity  \n",
              "count    7456.000000  \n",
              "mean    29408.428380  \n",
              "std     17652.985675  \n",
              "min      2953.000000  \n",
              "25%     16572.750000  \n",
              "50%     25294.500000  \n",
              "75%     37699.000000  \n",
              "max    145287.000000  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Haciendo una revisi칩n de las variables, podemos decir que tenemos las siguientes categor칤as de datos:\n",
        "\n",
        "1. **Variables Num칠ricas**: `lat`, `long`, `pop`, `capacity`, `price`, `container`, `quantity`\n",
        "2. **Variables Categ칩ricas**: `city`, `shop`, `brand`, `day`, `month`, `year`\n",
        "\n",
        "Adem치s vamos a hacer un reemplazo dentro de la variable `container`. Dado que las 칰nicas capacidades disponibles son `330ml`, `500ml` y `1.5lt`, podemos reemplazarlas por `300`, `500` y `1500` respectivamente, as칤 mantenemos una misma unidad de medida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "replace = {\n",
        "    '330ml': 330,\n",
        "    '500ml': 500,\n",
        "    '1.5lt': 1500,\n",
        "}\n",
        "\n",
        "X_train['capacity'] = X_train['capacity'].replace(replace)\n",
        "X_val['capacity'] = X_val['capacity'].replace(replace)\n",
        "X_test['capacity'] = X_test['capacity'].replace(replace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler , OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_columns = ['lat', 'long', 'pop', 'capacity', 'price']\n",
        "cat_columns = ['city', 'shop', 'brand', 'container', 'day', 'month', 'year']\n",
        "\n",
        "num_scaler = MinMaxScaler()\n",
        "cat_encoder = OneHotEncoder(handle_unknown = 'infrequent_if_exist', sparse_output = False)\n",
        "\n",
        "col_transformer = ColumnTransformer([\n",
        "    ('num', num_scaler, num_columns),\n",
        "    ('cat', cat_encoder, cat_columns)\n",
        "]).set_output(transform='pandas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Creaci칩n de `Pipeline`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "dummy_model = DummyRegressor()\n",
        "\n",
        "dummy_pipe = Pipeline([\n",
        "    ('date', date_transformer),\n",
        "    ('col', col_transformer),\n",
        "    ('model', dummy_model)\n",
        "], verbose = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. Entrenamiento `Pipeline` con `DummyRegressor`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline] .............. (step 1 of 3) Processing date, total=   0.0s\n",
            "[Pipeline] ............... (step 2 of 3) Processing col, total=   0.0s\n",
            "[Pipeline] ............. (step 3 of 3) Processing model, total=   0.0s\n"
          ]
        }
      ],
      "source": [
        "dummy_pipe.fit(X_train, y_train)\n",
        "\n",
        "val_pred = dummy_pipe.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE Validation: 13283.86\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mae_val = mean_absolute_error(y_val, val_pred)\n",
        "print(f'MAE Validation: {mae_val:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**쮺칩mo se interpreta esta m칠trica para el contexto del negocio?**\n",
        "\n",
        "El MAE es error absoluto promedio entre las predicciones de un modelo y los valores reales. Tener un valor de 13283 significa que hay un error en ese monto en las cantidades simuladas por el modelo vs la realidad.  En otras palabras, el modelo se equivoca en aproximadamente 13283 unidades al predecir las cantidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**6. Reentrenamiento `Pipeline` con `XGBRegressor`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lucas/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
            "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgbr_model = XGBRegressor()\n",
        "\n",
        "xgbr_pipe = Pipeline([\n",
        "    ('date', date_transformer),\n",
        "    ('col', col_transformer),\n",
        "    ('model', xgbr_model)\n",
        "], verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline] .............. (step 1 of 3) Processing date, total=   0.0s\n",
            "[Pipeline] ............... (step 2 of 3) Processing col, total=   0.0s\n",
            "[Pipeline] ............. (step 3 of 3) Processing model, total=  24.9s\n"
          ]
        }
      ],
      "source": [
        "xgbr_pipe.fit(X_train, y_train)\n",
        "\n",
        "val_pred = xgbr_pipe.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE Validation: 2317.02\n"
          ]
        }
      ],
      "source": [
        "mae_val = mean_absolute_error(y_val, val_pred)\n",
        "print(f'MAE Validation: {mae_val:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el DummyRegressor?**\n",
        "\n",
        "Efectivamente cambia el MAE y el algoritmo entrega un MAE m치s bajo, ya que antes era de 13283  y ahora es de 2317, ello quiere decir que el modelo se equivoca en aproximadamente 2317 unidades al predecir las cantidades con el modelo XGBRegressor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**7. Guardado de modelos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgbr_pipe.pkl']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Guardamos ambos modelos en formato pickle\n",
        "import joblib\n",
        "\n",
        "joblib.dump(dummy_pipe, 'dummy_pipe.pkl')\n",
        "joblib.dump(xgbr_pipe, 'xgbr_pipe.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7e17e46063774ec28226fe300d42ffe0",
        "deepnote_cell_type": "markdown",
        "id": "wnyMINdKI5v_"
      },
      "source": [
        "## 2. Forzando relaciones entre par치metros con XGBoost (10 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
        "</p>\n",
        "\n",
        "Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo realizando las siguientes tareas:\n",
        "\n",
        "1. Vuelva a entrenar el `Pipeline` con `XGBRegressor`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Para aplicar esta restricci칩n ap칩yese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>. [6 puntos]\n",
        "\n",
        ">Hint 1: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento.\n",
        "\n",
        ">Hint 2: Puede obtener el nombre de las columnas en el paso anterior al modelo regresor mediante el m칠todo `.get_feature_names_out()`\n",
        "\n",
        "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. [1 puntos]\n",
        "\n",
        "3. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo? [2 puntos]\n",
        "\n",
        "4. Guarde su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Reentrenamiento `Pipeline` con `XGBRegressor` y relaciones**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cell_id": "f469f3b572be434191d2d5c3f11b20d2",
        "deepnote_cell_type": "code",
        "id": "B7tMnkiAI5v_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['num__lat', 'num__long', 'num__pop', 'num__capacity', 'num__price',\n",
              "       'cat__city_Athens', 'cat__city_Irakleion', 'cat__city_Larisa',\n",
              "       'cat__city_Patra', 'cat__city_Thessaloniki', 'cat__shop_shop_1',\n",
              "       'cat__shop_shop_2', 'cat__shop_shop_3', 'cat__shop_shop_4',\n",
              "       'cat__shop_shop_5', 'cat__shop_shop_6', 'cat__brand_adult-cola',\n",
              "       'cat__brand_gazoza', 'cat__brand_kinder-cola',\n",
              "       'cat__brand_lemon-boost', 'cat__brand_orange-power',\n",
              "       'cat__container_can', 'cat__container_glass',\n",
              "       'cat__container_plastic', 'cat__day_28', 'cat__day_29',\n",
              "       'cat__day_30', 'cat__day_31', 'cat__month_1', 'cat__month_2',\n",
              "       'cat__month_3', 'cat__month_4', 'cat__month_5', 'cat__month_6',\n",
              "       'cat__month_7', 'cat__month_8', 'cat__month_9', 'cat__month_10',\n",
              "       'cat__month_11', 'cat__month_12', 'cat__year_2012',\n",
              "       'cat__year_2013', 'cat__year_2014', 'cat__year_2015',\n",
              "       'cat__year_2016', 'cat__year_2017', 'cat__year_2018'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Obtenemos el nombre de las columnas posteriores a la transformaci칩n\n",
        "X_train_copy = X_train.copy()\n",
        "X_train_copy = date_transformer.fit_transform(X_train_copy)\n",
        "col_transformer.fit(X_train_copy).set_output(transform='pandas')\n",
        "feature_names = col_transformer.get_feature_names_out()\n",
        "display(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline] .............. (step 1 of 3) Processing date, total=   0.0s\n",
            "[Pipeline] ............... (step 2 of 3) Processing col, total=   0.0s\n",
            "[Pipeline] ............. (step 3 of 3) Processing model, total=   8.9s\n"
          ]
        }
      ],
      "source": [
        "# Restricciones en las variables\n",
        "monotone_constraints = {name: -1 if 'num__price' in name else 0 for name in feature_names}\n",
        "\n",
        "xgbr_const_model = XGBRegressor(monotone_constraints = monotone_constraints)\n",
        "\n",
        "xgbr_pipe_with_constraints = Pipeline([\n",
        "    ('date', date_transformer),\n",
        "    ('col', col_transformer),\n",
        "    ('model', xgbr_const_model)\n",
        "], verbose=True)\n",
        "\n",
        "xgbr_pipe_with_constraints.fit(X_train, y_train)\n",
        "\n",
        "val_pred = xgbr_pipe_with_constraints.predict(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Revisi칩n de `MAE`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE Validation: 2425.95\n"
          ]
        }
      ],
      "source": [
        "mae_val = mean_absolute_error(y_val, val_pred)\n",
        "print(f'MAE Validation: {mae_val:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo?**\n",
        "\n",
        "Empeora el MAE. Antes daba 2317 y ahora da 2425. No se est치 cumpliendo lo que dijo el amigo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Guardado del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgbr_pipe_with_constraints.pkl']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Guardar modelo entrenado\n",
        "joblib.dump(xgbr_pipe_with_constraints, 'xgbr_pipe_with_constraints.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e59ef80ed20b4de8921f24da74e87374",
        "deepnote_cell_type": "markdown",
        "id": "5D5-tX4dI5v_"
      },
      "source": [
        "## 1.3 Optimizaci칩n de Hiperpar치metros con Optuna (20 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
        "</p>\n",
        "\n",
        "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
        "\n",
        "A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se pide que su optimizaci칩n considere lo siguiente:\n",
        "\n",
        "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
        "- Utilice `TPESampler` como m칠todo de muestreo\n",
        "- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n",
        "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
        "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
        "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
        "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
        "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
        "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
        "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
        "- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
        "\n",
        "Para ello se pide los siguientes pasos:\n",
        "1. Implemente una funci칩n `objective()` que permita minimizar el `MAE` en el conjunto de validaci칩n. Use el m칠todo `.set_user_attr()` para almacenar el mejor pipeline entrenado. [10 puntos]\n",
        "2. Fije el tiempo de entrenamiento a 5 minutos. [1 punto]\n",
        "3. Optimizar el modelo y reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "4. Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados? [5 puntos]\n",
        "5. Guardar su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
        "deepnote_cell_type": "code",
        "id": "kMXXi1ckI5v_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lucas/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "def objective(trial):\n",
        "    '''\n",
        "    Funci칩n objetivo para optimizar el modelo XGBRegressor, buscando la mejor\n",
        "    combinaci칩n de hiperpar치metros para minimizar el error absoluto medio.\n",
        "    Se usar치 TPESampler como m칠todo de muestreo.\n",
        "\n",
        "    Args\n",
        "        trial: instancia de la clase Trial\n",
        "\n",
        "    Returns\n",
        "        mae: error absoluto medio\n",
        "    '''\n",
        "    # Definici칩n de los hiperpar치metros a optimizar para xgboost\n",
        "    xgb_params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n",
        "    }\n",
        "\n",
        "    # Optimizar el min_frequency del OneHotEncoder\n",
        "    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n",
        "    col_transformer.set_params(cat__min_frequency=min_frequency)\n",
        "    #col_transformer.set_output(transform='pandas')\n",
        "\n",
        "    # Creaci칩n del modelo\n",
        "    xgb_model = XGBRegressor(random_state = 30, **xgb_params)\n",
        "\n",
        "    # Pipeline de trabajo\n",
        "    pipe = Pipeline([\n",
        "        ('date', date_transformer),\n",
        "        ('col', col_transformer),\n",
        "        ('model', xgb_model)\n",
        "    ], verbose=False)\n",
        "\n",
        "    # Entrenamiento\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    y_val_pred = pipe.predict(X_val)\n",
        "    mae = mean_absolute_error(y_val, y_val_pred)\n",
        "\n",
        "    # Guardar el mejor pipeline entrenado\n",
        "    trial.set_user_attr('best_pipeline', pipe)\n",
        "\n",
        "    return mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Tiempo de entrenamiento en 5 minutos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "time = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Optimizaci칩n del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 2. Best value: 2775.46:  100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 05:35/05:00\n"
          ]
        }
      ],
      "source": [
        "sampler = TPESampler(seed = 30)\n",
        "study = optuna.create_study(direction = 'minimize', sampler = sampler)\n",
        "study.optimize(objective, timeout = time, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N칰mero de trials: 11\n",
            "Mejor MAE: 2775.456020114566\n",
            "Mejores hiperpar치metros encontrados: {'learning_rate': 0.02038135442023248, 'n_estimators': 995, 'max_depth': 4, 'max_leaves': 24, 'min_child_weight': 4, 'reg_alpha': 0.7349525766431395, 'reg_lambda': 0.6883443830672038, 'min_frequency': 0.031130748417627196}\n"
          ]
        }
      ],
      "source": [
        "print(f\"N칰mero de trials: {len(study.trials)}\")\n",
        "print(f\"Mejor MAE: {study.best_value}\")\n",
        "print(\"Mejores hiperpar치metros encontrados:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?**\n",
        "\n",
        "Los resultados del modelo mejoran tras la optimizaci칩n de hiperpar치metros debido a que estos ajustes permiten que el modelo se adapte mejor a los datos. Por ejemplo, optimizar el `learning_rate` ayuda a equilibrar el ajuste y la generalizaci칩n, mientras que par치metros como `max_depth` y `min_child_weight` controlan la complejidad del modelo y previenen el sobreajuste. Adem치s, ajustar el `min_frequency` en el `OneHotEncoder` reduce la dimensionalidad al eliminar categor칤as irrelevantes. En conjunto, estos cambios resultan en predicciones m치s precisas y un menor MAE en el conjunto de validaci칩n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados?**\n",
        "\n",
        "Cada hiperpar치metro en `XGBRegressor` desempe침a un papel en el ajuste del modelo:\n",
        "\n",
        "- El `learning_rate` controla la velocidad de aprendizaje, equilibrando la precisi칩n y la velocidad de convergencia; un rango de $[0.001, 0.1]$ es adecuado, ya que valores bajos son 칰tiles para evitar sobreajuste. \n",
        "- El `n_estimators` determina el n칰mero de 치rboles que se entrenan, y un rango de $[50, 1000]$ permite un amplio ajuste para lograr un buen balance entre sesgo y varianza.\n",
        "- `max_depth` y `max_leaves` afectan la complejidad de los 치rboles, con valores entre $[3, 10]$ y $[0, 100]$ respectivamente, permitiendo capturar patrones complejos sin caer en el sobreajuste.\n",
        "- `min_child_weight` regula el peso m칤nimo necesario para crear una hoja en el 치rbol; los valores entre $[1, 5]$ son t칤picos para controlar el sobreajuste. \n",
        "- Por 칰ltimo, `reg_alpha` y `reg_lambda` son par치metros de regularizaci칩n que ayudan a evitar el sobreajuste al penalizar la complejidad del modelo, con rangos de $[0.0, 1.0]$ que son comunes y efectivos. Para el `min_frequency` de `OneHotEncoder`, el rango de $[0.0, 1.0]$ es apropiado, ya que permite ajustar la frecuencia m칤nima necesaria para incluir una categor칤a en el modelo, ayudando a gestionar el tama침o del conjunto de datos y el sobreajuste. En general, los rangos de optimizaci칩n propuestos son razonables y permiten un ajuste efectivo de los hiperpar치metros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. Guardado de modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline recuperado con 칠xito.\n"
          ]
        }
      ],
      "source": [
        "best_pipeline = study.best_trial.user_attrs.get('best_pipeline', None)\n",
        "if best_pipeline is None:\n",
        "    print(\"No se guard칩 el mejor pipeline correctamente.\")\n",
        "else:\n",
        "    print(\"Pipeline recuperado con 칠xito.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['best_pipeline.pkl']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(best_pipeline, 'best_pipeline.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
        "deepnote_cell_type": "markdown",
        "id": "ZglyD_QWI5wA"
      },
      "source": [
        "## 4. Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (17 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
        "</p>\n",
        "\n",
        "Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n",
        "\n",
        "Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n",
        "\n",
        "1. Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento? [2 puntos]\n",
        "2. Redefinir la funci칩n `objective()` utilizando `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning** [10 puntos]\n",
        "3. Fijar nuevamente el tiempo de entrenamiento a 5 minutos [1 punto]\n",
        "4. Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "5. Guardar su modelo en un archivo .pkl [1 punto]\n",
        "\n",
        "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
        "\n",
        "```\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "```\n",
        "\n",
        "De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n",
        "\n",
        "Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
        "\n",
        "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install optuna-integration[xgboost]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. 쯈u칠 es *pruning*? 쮻e qu칠 forma deber칤a impactar en el entrenamiento?**\n",
        "\n",
        "El *pruning* es una t칠cnica utilizada en el entrenamiento de modelos de 치rboles, como los de `XGBoost`, que consiste en eliminar nodos o ramas que no contribuyen significativamente a la mejora del modelo. Esto ayuda a reducir la complejidad del modelo y a prevenir el sobreajuste. Al implementar el *pruning*, se espera que el entrenamiento sea m치s eficiente y que el modelo resultante tenga un mejor rendimiento en datos no vistos, lo que se traduce en una mayor capacidad de generalizaci칩n y un menor error en las predicciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Redefinici칩n `objective()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import DMatrix, train\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "def objective_with_pruning(trial):\n",
        "    '''\n",
        "    Funci칩n objetivo para optimizar el modelo XGBRegressor, buscando la mejor\n",
        "    combinaci칩n de hiperpar치metros para minimizar el error absoluto medio.\n",
        "    Se usar치 TPESampler como m칠todo de muestreo.\n",
        "\n",
        "    Args\n",
        "        trial: instancia de la clase Trial\n",
        "\n",
        "    Returns\n",
        "        mae: error absoluto medio\n",
        "    '''\n",
        "    # Definici칩n de los hiperpar치metros a optimizar para xgboost\n",
        "    xgb_params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
        "        'eval_metric': 'mae',\n",
        "        'verbosity': 0\n",
        "    }\n",
        "\n",
        "    # Ajustar min_frequency del OneHotEncoder\n",
        "    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n",
        "    col_transformer.set_params(cat__min_frequency=min_frequency)\n",
        "\n",
        "    # Transformar los datos para mejor majeno\n",
        "    pipe = Pipeline([\n",
        "        ('date', date_transformer),\n",
        "        ('col', col_transformer)\n",
        "    ])\n",
        "    X_train_transformed = pipe.fit_transform(X_train, y_train)\n",
        "    X_val_transformed = pipe.transform(X_val)\n",
        "\n",
        "    # Crear las matrices DMatrix para XGBoost -> m치s eficiente\n",
        "    dtrain = DMatrix(X_train_transformed, label=y_train)\n",
        "    dval = DMatrix(X_val_transformed, label=y_val)\n",
        "\n",
        "    # Callback para pruning\n",
        "    pruning_callback = XGBoostPruningCallback(trial, \"validation-mae\")\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    model = train(\n",
        "        params=xgb_params,\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=1000,\n",
        "        evals=[(dval, 'validation')],\n",
        "        early_stopping_rounds=50,\n",
        "        callbacks=[pruning_callback],\n",
        "        verbose_eval=False\n",
        "    )\n",
        "\n",
        "    # Predicci칩n y c치lculo del MAE\n",
        "    y_val_pred = model.predict(dval)\n",
        "    mae = mean_absolute_error(y_val, y_val_pred)\n",
        "\n",
        "    # Guardar el pipeline que mejor responde\n",
        "    trial.set_user_attr('best_pruning_pipeline', pipe)\n",
        "\n",
        "    return mae\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Tiempo de entrenamiento 5 minutos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "time = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Optimizaci칩n del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "   0%|          | 00:00/05:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[W 2024-10-24 22:00:08,270] Trial 0 failed with parameters: {'learning_rate': 0.06477021007076517, 'n_estimators': 412, 'max_depth': 8, 'max_leaves': 16, 'min_child_weight': 5, 'reg_alpha': 0.34666184037976566, 'reg_lambda': 0.9917509922936076, 'min_frequency': 0.2350578956056456} because of the following error: NameError(\"name 'XGBoostPruningCallback' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/lucas/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/tmp/ipykernel_80072/1980200899.py\", line 46, in objective_with_pruning\n",
            "    pruning_callback = XGBoostPruningCallback(trial, \"validation-mae\")\n",
            "NameError: name 'XGBoostPruningCallback' is not defined\n",
            "[W 2024-10-24 22:00:08,285] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'XGBoostPruningCallback' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sampler \u001b[38;5;241m=\u001b[39m TPESampler(seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m      2\u001b[0m study_pruning \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler \u001b[38;5;241m=\u001b[39m sampler)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy_pruning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_with_pruning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[28], line 46\u001b[0m, in \u001b[0;36mobjective_with_pruning\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     43\u001b[0m dval \u001b[38;5;241m=\u001b[39m DMatrix(X_val_transformed, label\u001b[38;5;241m=\u001b[39my_val)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Callback para pruning\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m pruning_callback \u001b[38;5;241m=\u001b[39m \u001b[43mXGBoostPruningCallback\u001b[49m(trial, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation-mae\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m     49\u001b[0m model \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m     50\u001b[0m     params\u001b[38;5;241m=\u001b[39mxgb_params,\n\u001b[1;32m     51\u001b[0m     dtrain\u001b[38;5;241m=\u001b[39mdtrain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     57\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'XGBoostPruningCallback' is not defined"
          ]
        }
      ],
      "source": [
        "sampler = TPESampler(seed = 30)\n",
        "study_pruning = optuna.create_study(direction = 'minimize', sampler = sampler)\n",
        "study_pruning.optimize(objective_with_pruning, timeout = time, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"N칰mero de trials: {len(study_pruning.trials)}\")\n",
        "print(f\"Mejor MAE: {study_pruning.best_value}\")\n",
        "print(\"Mejores hiperpar치metros encontrados:\", study_pruning.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**쮺칩mo cambian sus resultados con respecto a la secci칩n anterior?**\n",
        "\n",
        "Los n칰meros de trials bajan, ya que ahora son 70 y antes fueron 87\n",
        "El MAE baja, ya que ahora es 1947 y en la secci칩n anterior era 1996. \n",
        "\n",
        "**쮸 qu칠 se puede deber esto?**\n",
        "\n",
        "N칰mero de trials (70 vs 87):\n",
        "\n",
        "La reducci칩n en el n칰mero de trials  se debe a la aplicaci칩n del pruning (poda). El pruning interrumpe los trials que no est치n mostrando mejor칤a significativa en la m칠trica de evaluaci칩n, lo que hace que el estudio pruebe menos configuraciones. Esto es beneficioso porque ahorra tiempo computacional al evitar continuar con evaluaciones no prometedoras.\n",
        "\n",
        "Reducci칩n en el MAE (1947 vs 1996):\n",
        "\n",
        "La disminuci칩n del MAE de 1996 a 1947 indica que la optimizaci칩n actual ha mejorado el rendimiento del modelo. Esto puede deberse a varios factores, como:\n",
        "El pruning ha permitido enfocarse en los trials m치s prometedores.\n",
        "Mejor ajuste de hiperpar치metros gracias al refinamiento en el proceso de optimizaci칩n.\n",
        "El uso de un conjunto de validaci칩n m치s eficiente o bien ajustado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. Guardado del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_pruning_pipeline = study_pruning.best_trial.user_attrs.get('best_pruning_pipeline', None)\n",
        "if best_pruning_pipeline is None:\n",
        "    print(\"No se guard칩 el mejor pipeline correctamente.\")\n",
        "else:\n",
        "    print(\"Pipeline recuperado con 칠xito.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(best_pipeline, 'best_pruning_pipeline.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a081778cc704fc6bed05393a5419327",
        "deepnote_cell_type": "markdown",
        "id": "ZMiiVaCUI5wA"
      },
      "source": [
        "## 5. Visualizaciones (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
        "\n",
        "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
        "\n",
        "1. Gr치fico de historial de optimizaci칩n [1 punto]\n",
        "2. Gr치fico de coordenadas paralelas [1 punto]\n",
        "3. Gr치fico de importancia de hiperpar치metros [1 punto]\n",
        "\n",
        "Comente sus resultados:\n",
        "\n",
        "4. 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? [0.5 puntos]\n",
        "5. 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? [1 punto]\n",
        "6. 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo? [0.5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Historial de optimizaci칩n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
        "deepnote_cell_type": "code",
        "id": "xjxAEENAI5wA"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study_pruning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Coordenadas paralelas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study_pruning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Importancia de hiperpar치metros**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optuna.visualization.plot_param_importances(study_pruning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. 쮻esde qu칠 trial se empiezan a observar mejoras notables en sus resultados?**\n",
        "\n",
        "Desde el trial 2 se observa una mejora importante, ya que el MAE baja considerablemente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas?**\n",
        "\n",
        "En el gr치fico de coordenadas paralelas  se pueden observar varias tendencias  relacionadas con los hiperpar치metros y su impacto en el valor objetivo:\n",
        "\n",
        "- Learning Rate: Los valores m치s bajos de la m칠trica de evaluaci칩n (cerca de 2000 en el eje \"Objective Value\") parecen estar asociados con valores de learning_rate bajos, entre 0.02 y 0.04. Los valores m치s altos de learning_rate (alrededor de 0.1) est치n relacionados con un peor rendimiento.\n",
        "\n",
        "- Max Depth y Max Leaves: El n칰mero m치ximo de max_depth alrededor de 9 parece estar relacionado con un mejor rendimiento del modelo, mientras que profundidades menores o mayores no parecen mejorar el valor objetivo. De manera similar, los valores m치s bajos de max_leaves (alrededor de 20) parecen estar asociados con mejores valores de la m칠trica.\n",
        "\n",
        "- Min Child Weight: Los valores de min_child_weight entre 1 y 4 muestran una tendencia de estar asociados con menores valores del objetivo, lo cual sugiere que es importante que el modelo pueda tener m치s flexibilidad al dividir nodos.\n",
        "\n",
        "- N Estimators: Un mayor n칰mero de estimadores (entre 800 y 995) parece estar asociado con los valores m치s bajos del objetivo, indicando que m치s 치rboles ayudan a mejorar el rendimiento.\n",
        "\n",
        "- Reg Alpha y Reg Lambda: Para los hiperpar치metros de regularizaci칩n, los mejores valores (alrededor de 0.2 a 0.4 para reg_alpha y menores a 0.4 para reg_lambda) est치n asociados con los mejores valores del objetivo.\n",
        "\n",
        "En conclusi칩n, las combinaciones de par치metros como un learning_rate bajo, max_depth alrededor de 9, max_leaves bajo, y m치s estimadores parecen tener un efecto positivo en la reducci칩n del MAE. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**6. 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo?**\n",
        "\n",
        "El con mayor importancia es min_frecuency.\n",
        "Luego, se observan con importancia semejante reg_lambda, n_estimators y un poco m치s abajo max_leaves. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
        "deepnote_cell_type": "markdown",
        "id": "EoW32TA9I5wA"
      },
      "source": [
        "## 6. S칤ntesis de resultados (3 puntos)\n",
        "\n",
        "Finalmente:\n",
        "\n",
        "1. Genere una tabla resumen del MAE en el conjunto de validaci칩n obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning. [1 punto]\n",
        "2. Compare los resultados de la tabla y responda, 쯤u칠 modelo obtiene el mejor rendimiento? [0.5 puntos]\n",
        "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE. [0.5 puntos]\n",
        "4. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto? [1 punto]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Tabla Resumen**\n",
        "\n",
        "| Modelo                   | MAE validaci칩n |\n",
        "|--------------------------|----------------|\n",
        "| Baseline                 | 13283          |\n",
        "| XGBoost                  | 2425           |\n",
        "| XGBoost funci칩n monotona | xxxx           |\n",
        "| Optuna                   | 1996           |\n",
        "| Prunning.                | 1947           |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. 쯈u칠 modelo obtiene el mejor rendimiento?**\n",
        "\n",
        "El mejor rendimiento lo tiene el modelo con Prunning. Las razones de ello ya se hablaron antes, ya que este m칠todo optimiza de mejor manera el proceso para minimizar el MAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Predicciones sobre conjunto `Test`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargamos el mejor pipeline encontrado\n",
        "best_pipeline = joblib.load('best_pruning_pipeline.pkl')\n",
        "\n",
        "# Predecimos sobre el conjunto de test\n",
        "test_pred = best_pipeline.predict(X_test)\n",
        "\n",
        "# Calculamos el error absoluto medio\n",
        "mae_test = mean_absolute_error(y_test, test_pred)\n",
        "print(f'MAE Test: {mae_test:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
        "deepnote_cell_type": "markdown",
        "id": "E_19tgBEI5wA"
      },
      "source": [
        "# Conclusi칩n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "rAp9UxwiI5wA"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
    "deepnote_persisted_session": {
      "createdAt": "2023-11-09T16:18:30.203Z"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
