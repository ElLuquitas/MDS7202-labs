{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8dd9b572c805487a9fb430fdc4ab12bb",
    "deepnote_cell_height": 156.26666259765625,
    "deepnote_cell_type": "markdown",
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 5: La desperaci√≥n de Mr. Cheems üêº</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d65413cd8566460dbceffcd13ca236e7",
    "deepnote_cell_type": "markdown",
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8e9217d02d124830a9b86046600a1605",
    "deepnote_cell_height": 172.13333129882812,
    "deepnote_cell_type": "markdown",
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
    "\n",
    "- Nombre de alumno 1: Lucas Orellana J.\n",
    "- Nombre de alumno 2: Elizabeth Ram√≠rez Z.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "010402b6d5f743b885a80d2e1c6ae11a",
    "deepnote_cell_height": 62.19999694824219,
    "deepnote_cell_type": "markdown",
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/ElLuquitas/MDS7202-labs.git)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ef0224c7a99e4b718b55493b0a1e99c4",
    "deepnote_cell_height": 724.9000244140625,
    "deepnote_cell_type": "markdown",
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "## Temas a tratar\n",
    "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
    "- Aplicar Pipelines y Column Transformers\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Jueves a las 23:59.\n",
    "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n",
    "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
    "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar procesos m√°s limpios en Feature Engineering.\n",
    "\n",
    "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "59664481c26f4ac4a753765269b1db6a",
    "deepnote_cell_height": 69.86666870117188,
    "deepnote_cell_type": "markdown",
    "id": "wrG4gYabzAHs"
   },
   "source": [
    "## Descripci√≥n del laboratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8c7bf8ea553d44c7a2efd61106a0bac2",
    "deepnote_cell_height": 61.866668701171875,
    "deepnote_cell_type": "markdown",
    "id": "MhISwri4zAHy"
   },
   "source": [
    "### Importamos librerias utiles üò∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T00:08:16.884674Z",
     "start_time": "2021-03-29T00:08:16.349846Z"
    },
    "cell_id": "67b4b29f0e6b48719b58d579276f2b19",
    "deepnote_cell_height": 514.13330078125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8517,
    "execution_start": 1635469788590,
    "id": "uyc33dKdzAHy",
    "source_hash": "a3741fd5"
   },
   "outputs": [],
   "source": [
    "# Libreria Core del lab.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Libreria para plotear (En colab esta desactualizado plotly)\n",
    "# !pip install --upgrade plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Librerias utiles\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "ce6a19ec6fc6486e832760ac3740d7ef",
    "deepnote_cell_height": 219.46665954589844,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1635165625274,
    "id": "gQ0-zPV4NNrq",
    "outputId": "a7c33afa-37fe-4965-de1a-53b8994c8c07",
    "source_hash": "c60dc4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignorando conexi√≥n drive-colab\n"
     ]
    }
   ],
   "source": [
    "# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    path = 'Direcci√≥n donde tiene los archivos en el Drive'\n",
    "except:\n",
    "    print('Ignorando conexi√≥n drive-colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "28c7a8b483d84878ac5a4f7ba882b711",
    "deepnote_cell_height": 133.86666870117188,
    "deepnote_cell_type": "markdown",
    "id": "QDwIXTh7bK_A",
    "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb"
   },
   "source": [
    "# Feature engineering en datos de retail üõçÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "160bb2695f6547448bfb0f99420f952c",
    "deepnote_cell_height": 69.86666870117188,
    "deepnote_cell_type": "markdown",
    "id": "_Eu4qBqnXMff",
    "tags": []
   },
   "source": [
    "### 0. Cargar Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6c6799ecc9e74272922d46a3b5a8b79e",
    "deepnote_cell_height": 294.683349609375,
    "deepnote_cell_type": "markdown",
    "id": "4shIzqqwXMfe",
    "tags": []
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=300 src=\"https://s1.eestatic.com/2018/04/14/social/la_jungla_-_social_299733421_73842361_854x640.jpg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "48d29c89e3b6455083f8fac764f97f3b",
    "deepnote_cell_height": 475.066650390625,
    "deepnote_cell_type": "markdown",
    "id": "cDpKjYRCXMfg",
    "tags": []
   },
   "source": [
    "Mr. Cheems, gerente de una cotizada tienda de retail en Europa, les solicita si pueden analizar los datos de algunas de sus tiendas. En una reuni√≥n, Mr Cheems le comenta que la calidad de sus datos no es muy buena, por lo que le solicita a usted que limpie su base de datos y cree nuevos atributos relevantes para el negocio.\n",
    "\n",
    "Por ello, el √°rea de ventas les entrega archivo llamado `online_retail_data.pickle` el cual usted decide cargar a continuaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "4d7d0f0855744e6c9d5a2198e5dcd690",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "deepnote_cell_height": 489.79998779296875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     177
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 466,
    "execution_start": 1635469797118,
    "id": "7FNOu-CvjV5m",
    "outputId": "90b4f92c-71df-44d4-8084-4dd06a6179e4",
    "source_hash": "d52b246c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID489434</td>\n",
       "      <td>85048</td>\n",
       "      <td>15CM CHRISTMAS GLASS BALL 20 LIGHTS</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.95</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID489434</td>\n",
       "      <td>79323P</td>\n",
       "      <td>PINK CHERRY LIGHTS</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID489434</td>\n",
       "      <td>79323W</td>\n",
       "      <td>WHITE CHERRY LIGHTS</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID489434</td>\n",
       "      <td>22041</td>\n",
       "      <td>RECORD FRAME 7\" SINGLE SIZE</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID489434</td>\n",
       "      <td>21232</td>\n",
       "      <td>STRAWBERRY CERAMIC TRINKET BOX</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Invoice StockCode                          Description  Quantity  \\\n",
       "0  ID489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS      12.0   \n",
       "1  ID489434    79323P                   PINK CHERRY LIGHTS      12.0   \n",
       "2  ID489434    79323W                  WHITE CHERRY LIGHTS      12.0   \n",
       "3  ID489434     22041         RECORD FRAME 7\" SINGLE SIZE       48.0   \n",
       "4  ID489434     21232       STRAWBERRY CERAMIC TRINKET BOX      24.0   \n",
       "\n",
       "          InvoiceDate  Price Customer ID         Country  \n",
       "0 2009-12-01 07:45:00   6.95     13085.0  United Kingdom  \n",
       "1                 NaT   6.75     13085.0  United Kingdom  \n",
       "2 2009-12-01 07:45:00   6.75     13085.0  United Kingdom  \n",
       "3 2009-12-01 07:45:00   2.10     13085.0  United Kingdom  \n",
       "4 2009-12-01 07:45:00   1.25     13085.0  United Kingdom  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserte su c√≥digo aqu√≠\n",
    "df_retail = pd.read_pickle('online_retail_data.pickle')\n",
    "df_retail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6nm_0uWvrFv"
   },
   "source": [
    "### 1. Funci√≥n para explorar caracter√≠sticas [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOZEZbbLoqfI"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=300 src=\"https://editor.analyticsvidhya.com/uploads/47389meme.png\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-7ZaNutk2GO"
   },
   "source": [
    "\n",
    "\n",
    "Tras inspeccionar brevemente los datos proporcionados, usted decide crear una funci√≥n que realice lo siguiente:\n",
    "- Plotee un histograma para las variables precios y cantidad. [3 puntos]\n",
    "- Imprima un conteo de datos nulos por variable [2 puntos]\n",
    "\n",
    "NOTA: Para generar los gr√°ficos es **OBLIGATORIO** el uso de plotly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM8FZ_4Yuiwi"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uDqT1Ljpk7vp"
   },
   "outputs": [],
   "source": [
    "def explore_data(dataframe_in, column_name = ['Price', 'Quantity']):\n",
    "    \"\"\"\n",
    "    Funci√≥n que permite:\n",
    "    - Hacer plot de histogramas para las variables `Price` y `Quantity`.\n",
    "    - Mostrar la cantidad de nulos por cada variable del dataset.\n",
    "\n",
    "    Args:\n",
    "      dataframe_in: DataFrame de pandas.\n",
    "      column_name: Nombre de la o las columnas a analizar.\n",
    "    \"\"\"\n",
    "\n",
    "    # Si hay una sola columna, graficarla\n",
    "    if isinstance(column_name, str):\n",
    "        fig = px.histogram(dataframe_in, x=column_name, title=f'Conteo de {column_name}')\n",
    "        fig.show()\n",
    "        return\n",
    "    \n",
    "    for col in column_name:\n",
    "        fig = px.histogram(dataframe_in, x=col, title=f'Conteo de {col}')\n",
    "        fig.show()\n",
    "\n",
    "    # Ahora mostramos los valores nulos\n",
    "    print('\\n Cantidad de nulos por variable:')\n",
    "    print(dataframe_in.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementar la funci√≥n \n",
    "explore_data(df_retail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4ZY_N0Ad1GP"
   },
   "source": [
    "### 2. Eliminando outliers [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXTpIi1Bo2KG"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=300 src=\"https://media.licdn.com/dms/image/C5612AQGdXKCka7HumA/article-cover_image-shrink_600_2000/0/1520056407281?e=2147483647&v=beta&t=VZcfjjzjK4LxXdZkSu1KisWC0Ry8bk4tPCn3R8aYdNM\">\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECqH4t-Jvj05"
   },
   "source": [
    "#### 2.1 Creando la clase IQR [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtCQGHN_mzEp"
   },
   "source": [
    "Entre las falencias de los datos, Mr. Cheems le comenta que a veces los operadores no ingresan el precio correcto de los productos. Mr. Cheems le comenta que se dio cuenta de este fen√≥meno porque hay productos con precios exager√°damente altos o bajos. Por lo cual usted decide eliminar outliers del dataframe a traves del rango intercuartil el cual cuenta con los siguientes pasos:\n",
    "\n",
    "1. Calcular el primer cuartil $Q1$ y el tercer cuartil $Q3$. Hint: utilice el m√©todo `quantile()`\n",
    "\n",
    "2. Calcular el rango intercuartil (RIC): $RIC = Q3 - Q1$\n",
    "\n",
    "3. Calcular los l√≠mites para identificar outliers:\n",
    " - L√≠mite inferior: $~~Q1 - \\lambda \\cdot RIC$\n",
    " - L√≠mite superior: $~~Q3 + \\lambda \\cdot RIC$\n",
    "\n",
    "4. Eliminar outliers: Los outliers son los datos que est√°n por debajo del l√≠mite inferior o por encima del l√≠mite superior.\n",
    "\n",
    "\n",
    "Para realizar dicha tarea, usted decide crear una clase llamada `IQR()` utilizando `BaseEstimator` y `TransformerMixin` para realizar una transformaci√≥n de cada una de las columnas num√©ricas del DataFrame utilizando `ColumnTransformer()` m√°s tarde. Considere que lambda debe ser $\\lambda$ un par√°metro a definir por el usuario.\n",
    "\n",
    "Hint: tome como referencia el siguiente [enlace](https://sklearn-template.readthedocs.io/en/latest/user_guide.html#transformer).\n",
    ">**Nota: No modificar el m√©todo set_output de la clase IQR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uqK6AZnuhmL"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n un esquema de c√≥mo se deben realizar los pasos para calcular los *outliers*. Tomamos como ejemplo la columna `Price`, pero se har√° aplicable para cualquier columna num√©rica:\n",
    "\n",
    "```py\n",
    "# Calcular primer cuartil Q_1 y tercer cuartil Q_3 usando `quantile`\n",
    "Q_1 = df_retail['Price'].quantile(0.25)\n",
    "Q_3 = df_retail['Price'].quantile(0.75)\n",
    "\n",
    "# Calcular rango intercuartil (RIC)\n",
    "RIC = Q_3 - Q_1\n",
    "\n",
    "# Definir los l√≠mites inferior y superior\n",
    "lambda_param = 1.5\n",
    "lower_bound = Q_1 - lambda_param * RIC\n",
    "upper_bound = Q_3 + lambda_param * RIC\n",
    "\n",
    "# Filtrar los datos\n",
    "df_retail_filtered = df_retail[(df_retail['Price'] > lower_bound) & (df_retail['Price'] < upper_bound)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQR(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  def __init__(self, lambda_param):\n",
    "    self.lambda_param = lambda_param\n",
    "\n",
    "  # Para el m√©todo `fit` se espera que hayan dos argumentos seg√∫n el link del hint,\n",
    "  # pero en este caso `y` se igualar√° a `None` para evitar posibles errores.\n",
    "  def fit(self, X, y = None):\n",
    "    Q_1 = X.quantile(0.25)\n",
    "    Q_3 = X.quantile(0.75)\n",
    "    RIC = Q_3 - Q_1\n",
    "    self.lower_bound = Q_1 - self.lambda_param * RIC\n",
    "    self.upper_bound = Q_3 + self.lambda_param * RIC\n",
    "\n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    # Para las transformaciones, trabajaremos sobre una copia de la columna\n",
    "    X_definitive = X.copy()\n",
    "\n",
    "    # Filtrar los datos\n",
    "    X_definitive = X_definitive[(X_definitive > self.lower_bound) & (X_definitive < self.upper_bound)]\n",
    "\n",
    "    return X_definitive\n",
    "\n",
    "  def set_output(self, transform = 'default'):\n",
    "    #No modificar esta funci√≥n\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pse94ohOm1um"
   },
   "source": [
    "#### 2.2 Creaci√≥n del Pipeline [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVWWiGA5m_Hj"
   },
   "source": [
    "Para comenzar introduci√©ndose en el uso de pipeline, usted decide definir un pipeline con el Transformer previamente definido. Adem√°s, usted decide visualizar c√≥mo cambia la distribuci√≥n de las variables Precio y Cantidad antes y despues de aplicar IQR. Para ello, usted aplica los siguientes pasos:\n",
    "\n",
    "- Definir un pipeline llamado `numeric_transformations` para las variables precio y cantidad con la transformaci√≥n IQR. [1 punto]\n",
    "- Defina un column transformer que aplique `numeric_transformations` para las variables num√©ricas y `passthrough` para las variables categ√≥ricas. Adicionalmente, fije el par√°metro `verbose_feature_names_out` en `False`. Ver hint al final [1 puntos]\n",
    "- Defina el dataframe `df_iqr` aplicado el column transformer a los datos proporcionados por Mr. Cheems considerando un valor de $\\lambda$ que tenga un desempe√±o aceptable para ambas variables. [1 punto]\n",
    "- Usar `explore_data` en `df_retail` y en `df_iqr`.  [1 punto]\n",
    "- Reportar los cambios observados en la distribuci√≥n de las variables. ¬øQu√© sucede al aumentar el valor de lambda? [1 punto]\n",
    "\n",
    "\n",
    "HINT: El transformador `passthrough` est√° predefinido y es una opci√≥n que puedes usar para las columnas que no deseas transformar. Al especificar 'passthrough' para una parte de tu ColumnTransformer, las columnas correspondientes pasar√°n a trav√©s del ColumnTransformer sin ninguna modificaci√≥n. El siguiente [enlace](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) le puede ser √∫til.\n",
    ">**Nota: Mantenga el m√©todo set_output del column transformer con la transformaci√≥n `pandas` para obtener un dataframe una vez aplicado el column transformer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkeizZcLuabD"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LF24vWb4GwLo"
   },
   "source": [
    "Ap√≥yese de la siguiente estructura para su respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZaSuz2NSn7g6"
   },
   "outputs": [],
   "source": [
    "# Definicion las variables que pasar√°n por cada pipeline\n",
    "numerical_columns = ('Price', 'Quantity')\n",
    "categorical_columns = ('Invoice', 'StockCode', 'Description', 'InvoiceDate', 'Customer ID', 'Country')\n",
    "\n",
    "# Definicion del pipeline\n",
    "numeric_transformations = Pipeline([('iqr', IQR(lambda_param = 1.5))])\n",
    "\n",
    "# ColumnTransformer\n",
    "column_transformer = ColumnTransformer([('numerical', numeric_transformations, numerical_columns),\n",
    "                                        ('categorical', 'passthrough', categorical_columns)\n",
    "                                        ],\n",
    "                                        verbose_feature_names_out = False)\n",
    "\n",
    "# Mantener el formato de pandas\n",
    "column_transformer.set_output(transform='pandas')\n",
    "\n",
    "# Aplicamos ColumnTransformer a los datos\n",
    "df_iqr = column_transformer.fit_transform(df_retail)\n",
    "\n",
    "# Gr√°ficos\n",
    "print('Datos originales:')\n",
    "explore_data(df_retail)\n",
    "\n",
    "print('\\nDatos despu√©s de aplicar IQR:')\n",
    "explore_data(df_iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPKnc6UcsDkm"
   },
   "source": [
    "**Reportar los cambios observados en la distribuci√≥n de las variables. ¬øQu√© sucede al aumentar el valor de lambda?**\n",
    "\n",
    "Al hacer los gr√°ficos de precio y cantidad con los datos entregados, se ve que hay *outliers* que hacen que los histogramas se vean con un rango amplio de datos. Al aplicar el filtro, podemos ver en los gr√°ficos que las observaciones ya no est√°n concentradas en la zona izquierda de cada histograma, existiendo una distribuci√≥n m√°s \"uniforme\". Los datos, tanto en cantidades como en precios, se concentraron en valores m√°s peque√±os en comparaci√≥n a los primeros datos, acot√°ndose los rangos entre los que var√≠an los valores de las dos variables analizadas, siendo los nuevos conjuntos (aprox):\n",
    "\n",
    "* `Price`: de $[0,0; 10000,0]$ a $[0,0; 7,5]$\n",
    "* `Quantity`: de $[0; 18000]$ a $[0;26]$\n",
    "\n",
    "Otro punto importante a notar es que la cantidad de nulos en las categor√≠as `Price` y `Quantity` aumentan. Esto dado que los m√©todos aplicados no eliminan las filas en donde existen los *outliers*, sino que reemplazan estos valores por valores nulos. Estos valores nulos ser√°n m√°s o menos dependiendo del par√°metro `lambda_param` que el usuario indique y del resultado que espera.\n",
    "\n",
    "El valor de lambda indica cu√°nta tolerancia hay para detectar *outliers*. B√°sicamente, controla qu√© tan lejos de los cuartiles $Q_1$ y $Q_3$ pueden estar los datos antes de ser considerados como valores *outliers*. En el ejercicio, decidimos usar un $\\lambda = 1.5$. Si aplicamos un $\\lambda = 2.0$, el rango de valores aumenta. \n",
    "* `Price` con $\\lambda = 2.0$: de $[0,0; 8,7]$\n",
    "* `Quantity` con $\\lambda = 2.0$: de $[1; 31]$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MF5s4dqMYCbJ"
   },
   "source": [
    "### 3. Agregando un imputer al pipeline [10 puntos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bc9fFeXp-At"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=300 src=\"https://media.makeameme.org/created/hmm-there-is.jpg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uugEdc26vJ5N"
   },
   "source": [
    "Para continuar con la limpieza del dataframe usted decide imputar los datos nulos de las variables num√©ricas, para lo cual decide realizar las siguientes tareas:\n",
    "\n",
    "1. Crear un pipeline para variables categ√≥ricas llamado `categoric_transformations` con un paso llamado `mode_imputer`, en el cual se imputen los datos faltantes por la categor√≠a m√°s frecuente.\n",
    "2. Agregar al pipeline `numeric_transformations` un paso llamado `mean_imputer`, en el cual se imputen los datos por la media usando [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) [1 punto]\n",
    "3. Crear y aplicar un `ColumnTransformer` actualizado con los pipelines `categoric_transformations` y `numeric_transformations` a `df_retail`, creando un dataframe llamado `df_mean_imputer`. [1 punto]\n",
    "4. Comparar los resultados de `explore_data` en `df_mean_imputer` y `df_iqr`. ¬øQu√© diferencias observa en la distribuci√≥n de los datos? [2 puntos]\n",
    "5. Cambiar el imputer de `numeric_transformations` por [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) y definir un nuevo dataframe llamado `df_knn_imputer`, aplicando el nuevo ColumnTransformer a `df_retail`. En caso de los tiempos de ejecuci√≥n sean altos puede probar a reducir el par√°metro `n_neighbors`. [1 punto]\n",
    "6. Comparar los resultados de `explore_data` en `df_knn_imputer` y `df_iqr`. ¬øQu√© diferencias observa en la distribuci√≥n de los datos? [2 puntos]\n",
    "7. Comparar los resultados de `explore_data` en `df_knn_imputer` y `df_mean_imputer`. ¬øCu√°l m√©todo de imputaci√≥n es mejor? Deje el m√©todo escogido en el ColumnTransformer. [2 puntos]\n",
    "\n",
    ">**Nota: Fije el par√°metro verbose_feature_names_out en `False` y utilice el m√©todo set_output con transformaci√≥n `pandas` en cada ColumnTransformer para obtener como salida un dataframe.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACVUdZZxuo4o"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n para SimpleImputer con estrategia mean (en segundos): 2.9319241046905518\n",
      "Tiempo de ejecuci√≥n para KNNImputer (en segundos): 1986.6127965450287\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Pipeline para variables categ√≥ricas (standard)\n",
    "categoric_transformation = Pipeline([('mode_imputer', SimpleImputer(strategy = 'most_frequent'))])\n",
    "\n",
    "# Pipeline para variables num√©ricas (mean)\n",
    "numeric_transformations_mean = Pipeline([('iqr', IQR(lambda_param = 1.5)),\n",
    "                                    ('mean_imputer', SimpleImputer(strategy = 'mean'))])\n",
    "\n",
    "# Pipeline para variables num√©ricas (KNN)\n",
    "numeric_transformations_knn = Pipeline([('iqr', IQR(lambda_param = 1.5)),\n",
    "                                    ('knn_imputer', KNNImputer(n_neighbors = 3))])\n",
    "\n",
    "# ColumnTransformer usando mean\n",
    "column_transformer_1 = ColumnTransformer([('numerical', numeric_transformations_mean, numerical_columns),\n",
    "                                        ('categorical', categoric_transformation, categorical_columns)\n",
    "                                        ],\n",
    "                                        verbose_feature_names_out = False)\n",
    "\n",
    "# ColumnTransformer usando KNN\n",
    "column_transformer_2 = ColumnTransformer([('numerical', numeric_transformations_knn, numerical_columns),\n",
    "                                        ('categorical', categoric_transformation, categorical_columns)\n",
    "                                        ],\n",
    "                                        verbose_feature_names_out = False)\n",
    "\n",
    "# Mantener el formato de pandas\n",
    "column_transformer_1.set_output(transform = 'pandas')\n",
    "column_transformer_2.set_output(transform = 'pandas')\n",
    "\n",
    "# Aplicamos ColumnTransformer a los datos\n",
    "init_mean = time.time()\n",
    "df_mean_imputer = column_transformer_1.fit_transform(df_retail)\n",
    "end_mean = time.time()\n",
    "print('Tiempo de ejecuci√≥n para SimpleImputer con estrategia mean (en segundos):', end_mean - init_mean)\n",
    "\n",
    "init_knn = time.time()\n",
    "df_knn_imputer = column_transformer_2.fit_transform(df_retail)\n",
    "end_knn = time.time()\n",
    "print('Tiempo de ejecuci√≥n para KNNImputer (en segundos):', end_knn - init_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8jgag-EYFai"
   },
   "outputs": [],
   "source": [
    "# 1. Gr√°ficos df_iqr \n",
    "print('Datos aplicando IQR:')\n",
    "explore_data(df_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Gr√°ficos df_mean_imputer \n",
    "print('\\nDatos aplicando IQR + imputaci√≥n media:')\n",
    "explore_data(df_mean_imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Gr√°ficos df_knn_imputer \n",
    "print('\\nDatos aplicando IQR + imputaci√≥n KNN:')\n",
    "explore_data(df_knn_imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PfBHpAsvSuD"
   },
   "source": [
    "**Comparar los resultados de explore_data en df_mean_imputer y df_iqr. ¬øQu√© diferencias observa en la distribuci√≥n de los datos?**\n",
    "\n",
    "* La mayor diferencia es que en el caso de `df_iqr` hay una gran cantidad de datos nulos, ya que se filtraron los *outliers* sin llegar a eliminar las observaciones. \n",
    "* En la distribuci√≥n de `Price` no se ve mayor diferencia, siendo estas m√≠nimas. \n",
    "* En la distribuci√≥n de `Quantity` s√≠ se ve una diferencia, ya que aparecen valores decimales, ya que se imputa por la media y esta puede tomar valores decimales, entonces aparecen m√°s barras en la distribuci√≥n. Esto no tiene tanto sentido en esta variable, ya que la cantidad en los datos de entrada ten√≠a valores de enteros. \n",
    "\n",
    "**Comparar los resultados de explore_data en df_knn_imputer y df_iqr. ¬øQu√© diferencias observa en la distribuci√≥n de los datos?**\n",
    "\n",
    "* Se observan diferencias. La primera es que `df_iqr` tiene valores nulos en el reporte que entrega la funci√≥n `explore_data`, mientras que `df_knn_imputer` no tiene valores nulos. \n",
    "* Con respecto a la columna `Price`, se ve que los rangos de las barras del histograma son m√°s acotados, mientras que en el KNN los rangos son mayores. La distribuci√≥n se parece, solo que hay diferencias en los valores que fueron imputados con el m√©todo KNN. \n",
    "* Con respecto a los valores de `Quantity`, se ve que la distribuci√≥n presenta mayores diferencias. Si bien la forma es similar, los valores imputados con KNN hacen que se formen  barras en el histograma m√°s angostas, porque los valores imputados hacen que cambie un poco la distribuci√≥n. \n",
    "\n",
    "**Comparar los resultados de explore_data en df_knn_imputer y df_mean_imputer. ¬øCu√°l m√©todo de imputaci√≥n es mejor? Deje el m√©todo escogido en el ColumnTransforme.**\n",
    "\n",
    "Con respecto a estos dos m√©todos, el m√©todo en que se obtiene el `df_mean_imputer` se demora bastante menos en ejecutarse que el m√©todo KNN en donde se obtiene el `df_knn_imputer`, como se pudo ver en el print del tiempo en segundos. \n",
    "\n",
    "Ambos m√©todos muestran que no hay valores nulos, ya que se realiz√≥ una imputaci√≥n para su rellenado. \n",
    "\n",
    "En la variable de `Quantity`, no se nota grandemente la diferencia en la distribuci√≥n de los datos, ya que ambos histogramas son bastante similares. \n",
    "En la variable `Price` se nota una mayor diferencia, ya que los rangos de precio en el histograma del KNN son m√°s amplios, mientras que en el histograma de la imputaci√≥n por la media los rangos con m√°s acotados y hay m√°s barras. La diferencia es que con la imputaci√≥n con la media queda m√°s variabilidad de valores, por esos se ve en el histograma barras m√°s acotadas, pero m√°s cantidad de barras en el rango entre $0$ a $7.5$, mientras que la imputaci√≥n con KNN estima los valores faltantes bas√°ndose en los valores de las observaciones m√°s cercanas y por eso se ven menos barras en total, pero con un ancho mayor, porque los datos faltantes los llena en base a los vecinos.\n",
    "En resumen, la imputaci√≥n con la media es m√°s simple y r√°pido que el m√©todo KNN, pero no considera los valores de alrededor del dato faltante. Por su parte, la imputaci√≥n con KNN, usa la similitud entre observaciones para estimar los valores faltantes, lo que lo hace m√°s preciso, pero m√°s costoso computacionalmente. \n",
    "\n",
    "Para terminar, no hay un m√©todo mejor, sino que depende de cada dataset. Si hay pocos datos faltantes, quiz√°s usar la imputaci√≥n por la media es recomendado, pero cuando faltan alta cantidad de datos, es mejor usar un m√©todo m√°s sofisticado. Dado que en este caso, los datos faltantes son $40382$ para `Price` y $33779$ en `Quantity`, creemos que en mejor usar KNN aunque sea m√°s costoso computacionalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buuUiW-9YYZ3"
   },
   "source": [
    "### 4. Creaci√≥n de nuevas features [20 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQSuoL5mubnA"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=250 src=\"https://miro.medium.com/max/1000/1*JtTWgAcfVTWV8OTjT47Atg.jpeg\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-yHP5oIvzFS"
   },
   "source": [
    "#### 4.1 Definicion de LRMFP [10 puntos]\n",
    "(2 puntos por cada custom feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe0V2CnZY8Bc"
   },
   "source": [
    "Dado que Mr. Lepin est√° interesado en obtener nuevos atributos relevantes para su negocio, su equipo de expertos sugiere la construcci√≥n de variables **LRMFP**, las que se construyen en base a las siguientes definiciones:\n",
    "\n",
    "- **Length (L)**: Intervalo de tiempo, en d√≠as, entre la primera y la √∫ltima visita del cliente. Mientras mas grande sea el valor, mas fiel es el cliente.\n",
    "\n",
    "- **Recency (R)**: Indica hace cuanto tiempo el cliente realizo su ultima compra. Notar que para este caso, mientras mas grande es el valor, menos interes posee el usuario para repetir una compra en uno de los locales. **Considere \"hoy\" como la fecha mas reciente del dataset**.\n",
    "\n",
    "- **Monetary (M)**: El t√©rmino \"monetario\" se refiere a la cantidad media de dinero gastada por cada visita del cliente durante el per√≠odo de observaci√≥n y refleja la contribuci√≥n del cliente a los ingresos de la empresa.\n",
    "\n",
    "- **Frequency (F)**: Se refiere al n√∫mero total de visitas del cliente durante el periodo de observaci√≥n. Cuanto mayor sea la frecuencia, mayor ser√° la fidelidad del cliente.\n",
    "\n",
    "- **Periodicity (P)**: Representa si los clientes visitan las tiendas con regularidad.\n",
    "\n",
    "$$Periodicity(n)=std(IVT_1, ..., IVT_n)$$\n",
    "\n",
    "Donde $IVT$ denota el tiempo entre visitas y n representa el n√∫mero de valores de tiempo entre visitas de un cliente.\n",
    "\n",
    "\n",
    "$$IVT_i=date\\_diff(t_{i+1},t)$$\n",
    "\n",
    "En base a las definiciones se√±aladas, dise√±e una funci√≥n que permita obtener las caracter√≠sticas **LRMFP** recibiendo un DataFrame como entrada. Para esto, no estar√° permitido el uso de iteradores, utilice todas las herramientas que les ofrece `pandas` para realizar esto.\n",
    "\n",
    "Una referencia que le puede ser √∫til es el [documento original](https://www.researchgate.net/publication/315979555_LRFMP_model_for_customer_segmentation_in_the_grocery_retail_industry_a_case_study) en donde se propone este m√©todo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bee8d549c7c043a5b0cafae0543afadf",
    "deepnote_cell_height": 212.6666717529297,
    "deepnote_cell_type": "markdown",
    "id": "L7ZwWJxhXMfk",
    "tags": []
   },
   "source": [
    "**<u>Formato</u> del Resultado Esperado:**\n",
    "\n",
    "| Customer ID | Length | Recency | Frequency | Monetary | Periodicity |\n",
    "|------------:|-------:|--------:|----------:|---------:|------------:|\n",
    "|   12346.0   |    294 |      67 |        46 |   -64.68 |        37.0 |\n",
    "|   12347.0   |     37 |       3 |        71 |  1323.32 |         0.0 |\n",
    "|   12349.0   |    327 |      43 |       107 |  2646.99 |        78.0 |\n",
    "|   12352.0   |     16 |      11 |        18 |   343.80 |         0.0 |\n",
    "|   12356.0   |     44 |      16 |        84 |  3562.25 |        12.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3c7f8a4a06a44cbd8d50e8a4decf4c71",
    "deepnote_cell_height": 52.26666259765625,
    "deepnote_cell_type": "markdown",
    "id": "6GaQZaMXXMfk",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "39a8b98eacdc43a4bdfeaa138b746198",
    "deepnote_cell_height": 83.86666870117188,
    "deepnote_cell_type": "code",
    "id": "VsgqgqsjXMfl",
    "owner_user_id": "8c58f50a-7a08-41a2-952e-38bdb7507048",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_features(dataframe_in):\n",
    "    '''\n",
    "    Funci√≥n que permite crear un nuevo dataframe con las siguientes columnas:\n",
    "    - Customer ID: Identificaci√≥n del cliente.\n",
    "    - Lenght: Intervalo de tiempo (d√≠as) entre la primera y √∫ltima visita.\n",
    "    - Recency: D√≠as desde la √∫ltima compra.\n",
    "    - Frequency: Total de visitas del cliente durante un periodo de observaci√≥n.\n",
    "    - Monetary: Gasto medio del cliente por cada visita durante un periodo de observaci√≥n.\n",
    "    - Periodicity: Primero calcula la diferencia de d√≠as entre una visita y otra, luego se calcula la desviaci√≥n est√°ndar.\n",
    "\n",
    "    Args:\n",
    "        dataframe_in: DataFrame de pandas.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame con las columnas descritas.\n",
    "    '''\n",
    "\n",
    "    # Creaci√≥n de columna Lenght\n",
    "    length_df = dataframe_in.groupby('Customer ID', observed = False)['InvoiceDate'].agg(Lenght = lambda x: (x.max() - x.min()).days)\n",
    "\n",
    "    # Creaci√≥n de columna Recency\n",
    "    today = dataframe_in['InvoiceDate'].max()\n",
    "    recency_df = dataframe_in.groupby('Customer ID', observed = False)['InvoiceDate'].agg(Recency = lambda x: (today - x.max()).days)\n",
    "\n",
    "    # Creaci√≥n de columna Frequency\n",
    "    frequency_df = dataframe_in.groupby('Customer ID', observed = False)['Invoice'].count().rename('Frequency')\n",
    "\n",
    "    # Creaci√≥n de columna Monetary\n",
    "    monetary_df = dataframe_in.groupby('Customer ID', observed = False)['Price'].mean().rename('Monetary')\n",
    "\n",
    "    # Creaci√≥n de columna Periodicity\n",
    "    # Primero ordeno las fechas y luego calculo la diferencia de d√≠as entre una visita y otra\n",
    "    periodicity_diff_df = dataframe_in.sort_values(by='InvoiceDate').groupby('Customer ID', observed = False)['InvoiceDate'].diff().dt.days\n",
    "    periodicity_df = periodicity_diff_df.groupby(dataframe_in['Customer ID']).std().rename('Periodicity')\n",
    "\n",
    "    # Concatenaci√≥n de las columnas, haciendo merge con la columna 'Customer ID'\n",
    "    df_custom = pd.concat([length_df, recency_df, frequency_df, monetary_df, periodicity_df], axis = 1)\n",
    "\n",
    "    ### Algunos arreglos a las columnas ###\n",
    "    # Redondeo de las columnas 'Monetary' y 'Periodicity' a 1 decimal\n",
    "    df_custom['Monetary'] = df_custom['Monetary'].round(1)\n",
    "    df_custom['Periodicity'] = df_custom['Periodicity'].round(1)\n",
    "\n",
    "    # Rellenar los valores nulos en 'Periodicity'con 0 (si no hay visitas, la periodicidad es indefinida)\n",
    "    df_custom['Periodicity'] = df_custom['Periodicity'].fillna(0)\n",
    "\n",
    "    return df_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_14884\\2204213945.py:34: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lenght</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Monetary</th>\n",
       "      <th>Periodicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12346.0</th>\n",
       "      <td>196.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>33</td>\n",
       "      <td>6.3</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347.0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349.0</th>\n",
       "      <td>181.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>102</td>\n",
       "      <td>8.6</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12351.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lenght  Recency  Frequency  Monetary  Periodicity\n",
       "Customer ID                                                   \n",
       "12346.0       196.0    164.0         33       6.3         22.1\n",
       "12347.0        37.0      2.0         71       2.2          4.5\n",
       "12348.0         0.0     73.0         20       0.7          0.0\n",
       "12349.0       181.0     42.0        102       8.6         16.3\n",
       "12351.0         0.0     10.0         21       2.4          0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_custom_features = custom_features(df_retail)\n",
    "df_custom_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de nulos en df_custom_features:\n",
      "Lenght         3\n",
      "Recency        3\n",
      "Frequency      0\n",
      "Monetary       2\n",
      "Periodicity    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de nulos en df_custom\n",
    "print('Cantidad de nulos en df_custom_features:')\n",
    "print(df_custom_features.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ddL8wThv36t"
   },
   "source": [
    "#### 4.2 Agregando las custom features [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehLWiQzjwDm-"
   },
   "source": [
    "Ahora, usted decide agregar al pipeline las nuevas variables creadas, para lo cual realiza las siguientes tareas:\n",
    "\n",
    "1. Cree un nuevo pipeline llamado `retail_pipeline` que encapsule el ColumnTransformer y calcule las LRMFP. El primer paso del pipeline ll√°melo  `col_tranformer` y el segundo paso ll√°melo `custom_features`, incorpora las nuevas variables al dataframe. Hint: les puede ser √∫til investigar [este](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) m√©todo. [1 punto]\n",
    "2. Aplicar el pipeline actualizado a los datos proporcionados por Mr. Cheems, creando un nuevo dataframe llamado `df_custom`. [1 punto]\n",
    "3. Explorar la distribuci√≥n de las nuevas variables con `explore_data` y comentar brevemente (2-3 l√≠neas) caracter√≠sticas de cada custom feature. [5 puntos]\n",
    "5. Entregar un insight para el negocio en base a las nuevas variables. [3 puntos]\n",
    "\n",
    ">Nota: Recuerde fijar el par√°metro `verbose_feature_names_out` en `False` e incorporar el m√©todo `set_output` para obtener una salida en formato dataframe del ColumnTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVCGxPgtwFsk"
   },
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JxILi3w0wE9Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n (en segundos): 1955.9095599651337\n"
     ]
    }
   ],
   "source": [
    "# ColumnTransformer usando KNN\n",
    "retail_pipeline = Pipeline([('col_transformer', column_transformer_2),\n",
    "                            ('custom_features', FunctionTransformer(custom_features, validate = False))])\n",
    "\n",
    "# Mantener el formato de pandas (viene de arriba, as√≠ que no hay problema)\n",
    "init = time.time()\n",
    "df_custom = retail_pipeline.fit_transform(df_retail)\n",
    "end = time.time()\n",
    "print('Tiempo de ejecuci√≥n (en segundos):', end - init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n de los nuevos datos\n",
    "explore_data(df_custom, df_custom.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explorar la distribuci√≥n de las nuevas variables con explore_data y comentar brevemente (2-3 l√≠neas) caracter√≠sticas de cada custom feature.**\n",
    "\n",
    "* La variable `Lenght` tiene una distribuci√≥n con alto valores en el rango entre 0 a 9 (la mayor concentraci√≥n de datos). Luego tiene dos concentraciones de datos hacia la derecha, una entre 200 a 290 y otra entre 320 a 380. \n",
    "* La variable `Recency` muestra una distribuci√≥n como una logar√≠tmica o gamma, con concentraci√≥n de datos hacia el cero y una disminuci√≥n alta de frecuencia hacia valores mayores. \n",
    "* La variable `Frecuency` tambi√©n muestra una distribuci√≥n como una logar√≠tmica, con un peak en torno al 0 y una ca√≠da r√°pida hacia valores mayores. \n",
    "* La variable `Monetary` tiene una distribuci√≥n similar a la normal, solo que tiene una peque√±a asimetr√≠a, ya que hay m√°s valores hacia la cola derecha que la izquierda. \n",
    "* La variable `Periodicity` tiene una alta concentraci√≥n de datos entorno al cero y luego tiene una distribuci√≥n que se pareciera a la normal pero con asimetr√≠a, ya que la cola derecha se prolonga mucho m√°s que la cola izquierda. \n",
    "\n",
    "**Entregar un insight para el negocio en base a las nuevas variables.**\n",
    "\n",
    "* Hay una gran cantidad de clientes que no son fieles clientes (sobre los 1000 clientes) que solo compraron 1 vez. Sin embargo, hay dos grupos de clientes que compran con m√°s frecuencia: un grupo en torno a 250 d√≠as y otro entorno a 350 dias de fidelidad como clientes. \n",
    "* La mayor cantidad de clientes realiz√≥ compras recientemente, entre 0 a 30 d√≠as. La cantidad de clientes que no ha vuelto a comprar es menor en comparaci√≥n a los clientes que compraron recientemente. \n",
    "* La frecuencia de los clientes tiende a estar concentrada en valores menores a 60 veces en el per√≠odo analizado, por lo que los clientes no tienden a hacer compras tan seguido. \n",
    "* Con respecto al t√©rmino monetario, la mayor parte de los clientes est√°n en torno a 2.2 de contribuci√≥n a la empresa con sus compras. Solo una menor cantidad sobrepasa el valor de 4. \n",
    "* Finalmente, la periodicidad de los clientes se concentra en torno a 0, es decir, no tienen periodicidad. Sin embargo hay un grupo de 250 clientes que se concentra en torno a 10 de periodicidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOV0y-e_lS39"
   },
   "source": [
    "### 5. MinMax Scaler [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T55ZgReXvjGe"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=300 src=\"https://i.imgflip.com/1fsprn.jpg\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dk2R1kvuu-e"
   },
   "source": [
    "#### 5.1 Definici√≥n del Column Transformer [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "94c48775ecb4496d970fbd920f65c126",
    "deepnote_cell_height": 268.70001220703125,
    "deepnote_cell_type": "markdown",
    "id": "iWsfp1dKXMfo",
    "tags": []
   },
   "source": [
    "Construya una clase llamada `MinMax()` para realizar una transformaci√≥n de cada una de las columnas de un DataFrame utilizando `ColumnTransformer()`. Recuerde  usar `BaseEstimator` y `TransformerMixin`.\n",
    "\n",
    "\n",
    " Para esto considere que Min-Max escaler queda dada por la ecuaci√≥n:\n",
    "\n",
    "$$MinMax = \\dfrac{x-min(x)}{max(x) - min(x)}$$\n",
    "\n",
    "\n",
    "Consulte el siguiente [link](https://sklearn-template.readthedocs.io/en/latest/user_guide.html#transformer) si tiene dudas sobre la creaci√≥n de custom transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c087d1fa8aa94d7485fe1292bf628660",
    "deepnote_cell_height": 52.26666259765625,
    "deepnote_cell_type": "markdown",
    "id": "MUOLTWPDXMfo",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "07cb4dcf097c4c6baabb9ae2bda25caf",
    "deepnote_cell_height": 83.86666870117188,
    "deepnote_cell_type": "code",
    "id": "g15ZMCs-XMfo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MinMax(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        # B√∫squeda de los valores m√≠nimos y m√°ximos dentro de la columna\n",
    "        self.min_x = X.min()\n",
    "        self.max_x = X.max()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_scaled = X.copy()\n",
    "        # Aplico la funci√≥n minmax\n",
    "        X_scaled = (X_scaled - self.min_x) / (self.max_x - self.min_x)\n",
    "        return X_scaled\n",
    "\n",
    "    def set_output(self, transform = 'default'):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RySqWq1Muzp8"
   },
   "source": [
    "#### 5.2 Incorporando MinMax al pipeline [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmIqjkgDwRsV"
   },
   "source": [
    "Ahora, usted decide agregar el escalamiento al pipeline, para lo que decide seguir los siguientes pasos:\n",
    "\n",
    "- Agregar el paso `minmax` al pipeline `numeric_transformations`, haciendo uso de la clase creada. [1 punto]\n",
    "- Defina el dataframe `df_minmax` aplicando el ColumnTransformer actualizado a los datos proporcionados por Mr. Cheems. [1 punto]\n",
    "- Usar `explore_data` en `df_retail` y en `df_minmax`. [1 punto]\n",
    "- Reportar los cambios observados en la distribuci√≥n de las variables.  [2 puntos]\n",
    "\n",
    ">Nota: Recuerde fijar el par√°metro `verbose_feature_names_out` en `False` e incorporar el m√©todo `set_output` para obtener una salida en formato dataframe del ColumnTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a480355952a34b6cb7e72afa764091d6",
    "deepnote_cell_height": 52.26666259765625,
    "deepnote_cell_type": "markdown",
    "id": "lL2_CyAGXMfp",
    "tags": []
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "1889976b7a4c40c7825752979b577567",
    "deepnote_cell_height": 65.86666870117188,
    "deepnote_cell_type": "code",
    "id": "NmApXgB8XMfp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecuci√≥n (en segundos): 1951.525897026062\n"
     ]
    }
   ],
   "source": [
    "# Definicion las variables que pasar√°n por cada pipeline\n",
    "numerical_columns = ('Price', 'Quantity')\n",
    "categorical_columns = ('Invoice', 'StockCode', 'Description', 'InvoiceDate', 'Customer ID', 'Country')\n",
    "\n",
    "# Pipeline para variables categ√≥ricas (standard)\n",
    "categoric_transformation = Pipeline([('mode_imputer', SimpleImputer(strategy = 'most_frequent'))])\n",
    "\n",
    "# Pipeline para variables num√©ricas (uso de KNN)\n",
    "numeric_transformations = Pipeline([('iqr', IQR(lambda_param = 1.5)),\n",
    "                                         ('knn_imputer', KNNImputer(n_neighbors = 3)),\n",
    "                                         ('min_max', MinMax())])\n",
    "\n",
    "# ColumnTransformer\n",
    "column_transformer = ColumnTransformer([('numerical', numeric_transformations, numerical_columns),\n",
    "                                        ('categorical', categoric_transformation, categorical_columns)\n",
    "                                        ],\n",
    "                                        verbose_feature_names_out = False)\n",
    "\n",
    "# Mantener el formato de pandas\n",
    "column_transformer.set_output(transform = 'pandas')\n",
    "\n",
    "# Aplicamos ColumnTransformer a los datos\n",
    "init = time.time()\n",
    "df_minmax = column_transformer.fit_transform(df_retail)\n",
    "end = time.time()\n",
    "print('Tiempo de ejecuci√≥n (en segundos):', end - init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos\n",
    "print('Datos originales:')\n",
    "explore_data(df_retail)\n",
    "\n",
    "print('\\nDatos despu√©s de aplicar MinMax:')\n",
    "explore_data(df_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reportar los cambios observados en la distribuci√≥n de las variables**\n",
    "\n",
    "Los valores cambiaron el rango entre el que oscilan. Despu√©s de aplicar la funci√≥n, ambas variables oscilan entre 0 a 1, teniendo una clara normalizaci√≥n de los valores. En esta parte ya se ve el efecto acumulativo de todos los pasos previos, por lo que ya no hay *outliers* y est√° la imputaci√≥n elegida antes. La forma de la distribuci√≥n se parece a las obtenidas antes, pero el rango es el que cambia, ya que se aplic√≥ la clase `MinMax`. Es importante que para aplicar esta clase hay que sacar los *outliers* antes, ya que `MinMax` se ver√≠a afectada por valores at√≠picos, ensuciando as√≠ las distribuciones. \n",
    "\n",
    "Tambi√©n se ve la diferencia en los datos nulos: el dataframe que tiene aplicada la funci√≥n MinMax ya no tiene valores nulos gracias al *pipeline* creado para eliminar valores e imputar nuevos en su primera etapa antes de la normalizaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWXlAO8-wfNt"
   },
   "source": [
    "### 6. Pregunta te√≥rica [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvsFRwpVtMh_"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=300 src=\"https://file.coinexstatic.com/2023-09-19/166BAC031F222E5910954E7D7D0BC844.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou7lQIAHwiZv"
   },
   "source": [
    "Finalmente, expl√≠quele a Mr. Cheems porqu√© es √∫til la creaci√≥n de pipelines al momento de hacer Feature Engineering en Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29QJyzOCwjdD"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMDYYL1stUVO"
   },
   "source": [
    "Crear pipelines en Python para el Feature Engineering en Machine Learning es muy √∫til porque organiza y simplifica el proceso de transformaci√≥n de datos. En los ejercicios, por ejemplo, usamos pipelines para imputar datos faltantes y aplicar transformaciones como MinMax o IQR de forma ordenada. Esto no solo hace que el c√≥digo sea m√°s f√°cil de entender y mantener, sino que tambi√©n permite aplicar las mismas transformaciones de manera consistente a diferentes conjuntos de datos. Adem√°s, los pipelines ayudan a evitar errores al automatizar pasos, asegurando que todas las transformaciones se apliquen correctamente antes de entrenar un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "94721075d5ff44bd83601c871797ae2a",
    "deepnote_cell_height": 514.4666748046875,
    "deepnote_cell_type": "markdown",
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "# Conclusi√≥n\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por el foro de U-cursos o por correo.\n",
    "\n",
    "![Gracias Totales!](https://i.pinimg.com/originals/65/ae/27/65ae270df87c3c4adcea997e48f60852.gif \"bruno\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7e31a91f8cb744cabd0ed0287ac5257e",
    "deepnote_cell_height": 171.28334045410156,
    "deepnote_cell_type": "markdown",
    "id": "wCL1lACBzAH7"
   },
   "source": [
    "<br>\n",
    "<center>\n",
    "<img src=\"https://i.kym-cdn.com/photos/images/original/001/194/195/b18.png\" width=100 height=50 />\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "id": "ALHqwrAFXMgD"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Q6nm_0uWvrFv",
    "buuUiW-9YYZ3",
    "1ddL8wThv36t",
    "qOV0y-e_lS39",
    "iWXlAO8-wfNt"
   ],
   "provenance": []
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "33c253a4f84d40a091bd5023e95abb64",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
