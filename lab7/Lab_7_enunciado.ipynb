{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 7: Clasificación 🤗\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos - Primavera 2024</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicolás Ojeda, Melanie Peña, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
        "\n",
        "- Nombre de alumno 1:\n",
        "- Nombre de alumno 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/...../)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificación en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- Código que no se pueda ejecutar, no será revisado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender cómo trabajar con problemas de clasificación con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Teórica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cuál es la diferencia entre los datos de entrenamiento y validación. [1 punto]\n",
        "\n",
        "2. Explique cuál es el principal desafío al trabajar problemas de clasificación con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qué es la matriz de confusión y para qué se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la fórmula de las siguientes métricas y explique con **sus palabras** cómo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qué métrica recomendaría para los siguientes contextos de clasificación. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detección de enfermedades altamente contagiosas.\n",
        "  * Aprobación de créditos de alto riesgo.\n",
        "  * Detección de crímenes.\n",
        "\n",
        "6. Explique qué es la calibración de modelos y para qué se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "*Escriba su respuesta aquí*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte práctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/61L8z0w/renacin-by-volframio-dcirf4l-fullview.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "Tras el trágico despido de la mítica mascota de Maipú, Renacín decide adentrarse como consultor en el mercado futbolero, el cuál (para variar...) está cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea será asesorar a los directivos de los clubes sobre cuál jugador comprar y cuál no, Renacín desea generar modelos predictivos que evaluén distintas características de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condición de corporeo le impidió tomar la versión anterior de MDS7202, por lo que este motivo Renacín contrata a su equipo para lograr su objetivo final. Dado que aún tiene fuertes vínculos con la dirección de deportes de la municipalidad, el corporeo le entrega base de datos con las estadísticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deberán trabajar con el csv `statsplayers.csv`, donde deberán aplicar algoritmos de aprendizaje supervisado de clasificación en base a características que describen de jugadores de fútbol.\n",
        "\n",
        "Para comenzar cargue el dataset señalado y a continuación vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las características principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mX6iwOWUfrp_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexión drive-colab\n"
          ]
        }
      ],
      "source": [
        "# Si usted está utilizando Colabolatory le puede ser útil este código para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = 'Dirección donde tiene los archivos en el Drive'\n",
        "except:\n",
        "    print('Ignorando conexión drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicción de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificación binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su país. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, ¿cuántos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y guárdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Generación de *labels*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JhC2sZj9dSI1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>National_Position</th>\n",
              "      <th>Club_Position</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Preffered_Foot</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Rate</th>\n",
              "      <th>Weak_foot</th>\n",
              "      <th>...</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Shot_Power</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>Long_Shots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>Freekick_Accuracy</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>LS</td>\n",
              "      <td>LW</td>\n",
              "      <td>185</td>\n",
              "      <td>80</td>\n",
              "      <td>Right</td>\n",
              "      <td>32</td>\n",
              "      <td>High / Low</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>85</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>90</td>\n",
              "      <td>81</td>\n",
              "      <td>76</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>RW</td>\n",
              "      <td>RW</td>\n",
              "      <td>170</td>\n",
              "      <td>72</td>\n",
              "      <td>Left</td>\n",
              "      <td>29</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>85</td>\n",
              "      <td>95</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>74</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Neymar</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>LW</td>\n",
              "      <td>LW</td>\n",
              "      <td>174</td>\n",
              "      <td>68</td>\n",
              "      <td>Right</td>\n",
              "      <td>25</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>61</td>\n",
              "      <td>62</td>\n",
              "      <td>78</td>\n",
              "      <td>89</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>84</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Luis Suárez</td>\n",
              "      <td>Uruguay</td>\n",
              "      <td>LS</td>\n",
              "      <td>ST</td>\n",
              "      <td>182</td>\n",
              "      <td>85</td>\n",
              "      <td>Right</td>\n",
              "      <td>30</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>69</td>\n",
              "      <td>77</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manuel Neuer</td>\n",
              "      <td>Germany</td>\n",
              "      <td>GK</td>\n",
              "      <td>GK</td>\n",
              "      <td>193</td>\n",
              "      <td>92</td>\n",
              "      <td>Right</td>\n",
              "      <td>31</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name Nationality National_Position Club_Position  Height  \\\n",
              "0  Cristiano Ronaldo    Portugal                LS            LW     185   \n",
              "1       Lionel Messi   Argentina                RW            RW     170   \n",
              "2             Neymar      Brazil                LW            LW     174   \n",
              "3        Luis Suárez     Uruguay                LS            ST     182   \n",
              "4       Manuel Neuer     Germany                GK            GK     193   \n",
              "\n",
              "   Weight Preffered_Foot  Age        Work_Rate  Weak_foot  ...  Agility  \\\n",
              "0      80          Right   32       High / Low          4  ...       90   \n",
              "1      72           Left   29  Medium / Medium          4  ...       90   \n",
              "2      68          Right   25    High / Medium          5  ...       96   \n",
              "3      85          Right   30    High / Medium          4  ...       86   \n",
              "4      92          Right   31  Medium / Medium          4  ...       52   \n",
              "\n",
              "   Jumping  Heading  Shot_Power  Finishing  Long_Shots  Curve  \\\n",
              "0       95       85          92         93          90     81   \n",
              "1       68       71          85         95          88     89   \n",
              "2       61       62          78         89          77     79   \n",
              "3       69       77          87         94          86     86   \n",
              "4       78       25          25         13          16     14   \n",
              "\n",
              "   Freekick_Accuracy  Penalties  Volleys  \n",
              "0                 76         85       88  \n",
              "1                 90         74       85  \n",
              "2                 84         81       83  \n",
              "3                 84         85       88  \n",
              "4                 11         47       11  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('stats_players.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generación de columna 'label' en base a columna 'National_Position'\n",
        "df['label'] = df['National_Position'].apply(lambda x: 1 if pd.notnull(x) else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Conteo de clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    16513\n",
              "1     1075\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se puede ver, existen $16.513$ jugadores que no poseen una posición definida en su selección nacional, habiendo en cambio $1.075$ que sí tienen una posición en la selección nacional de su país."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Generación de `ColumnTransformer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Name                 object\n",
              "Nationality          object\n",
              "National_Position    object\n",
              "Club_Position        object\n",
              "Height                int64\n",
              "Weight                int64\n",
              "Preffered_Foot       object\n",
              "Age                   int64\n",
              "Work_Rate            object\n",
              "Weak_foot             int64\n",
              "Skill_Moves           int64\n",
              "Ball_Control          int64\n",
              "Dribbling             int64\n",
              "Marking               int64\n",
              "Sliding_Tackle        int64\n",
              "Standing_Tackle       int64\n",
              "Aggression            int64\n",
              "Reactions             int64\n",
              "Interceptions         int64\n",
              "Vision                int64\n",
              "Composure             int64\n",
              "Crossing              int64\n",
              "Short_Pass            int64\n",
              "Long_Pass             int64\n",
              "Acceleration          int64\n",
              "Speed                 int64\n",
              "Stamina               int64\n",
              "Strength              int64\n",
              "Balance               int64\n",
              "Agility               int64\n",
              "Jumping               int64\n",
              "Heading               int64\n",
              "Shot_Power            int64\n",
              "Finishing             int64\n",
              "Long_Shots            int64\n",
              "Curve                 int64\n",
              "Freekick_Accuracy     int64\n",
              "Penalties             int64\n",
              "Volleys               int64\n",
              "label                 int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Primero veremos el tipo de dato en cada columna.\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Age</th>\n",
              "      <th>Weak_foot</th>\n",
              "      <th>Skill_Moves</th>\n",
              "      <th>Ball_Control</th>\n",
              "      <th>Dribbling</th>\n",
              "      <th>Marking</th>\n",
              "      <th>Sliding_Tackle</th>\n",
              "      <th>Standing_Tackle</th>\n",
              "      <th>...</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Shot_Power</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>Long_Shots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>Freekick_Accuracy</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17588.00000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>181.10547</td>\n",
              "      <td>75.253355</td>\n",
              "      <td>25.460314</td>\n",
              "      <td>2.934103</td>\n",
              "      <td>2.303161</td>\n",
              "      <td>57.972766</td>\n",
              "      <td>54.802877</td>\n",
              "      <td>44.230327</td>\n",
              "      <td>45.565499</td>\n",
              "      <td>47.441096</td>\n",
              "      <td>...</td>\n",
              "      <td>64.918524</td>\n",
              "      <td>52.393109</td>\n",
              "      <td>55.581192</td>\n",
              "      <td>45.157607</td>\n",
              "      <td>47.403173</td>\n",
              "      <td>47.181146</td>\n",
              "      <td>43.383443</td>\n",
              "      <td>49.165738</td>\n",
              "      <td>43.275586</td>\n",
              "      <td>0.061121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.67516</td>\n",
              "      <td>6.897948</td>\n",
              "      <td>4.680217</td>\n",
              "      <td>0.655927</td>\n",
              "      <td>0.746156</td>\n",
              "      <td>16.834779</td>\n",
              "      <td>18.913857</td>\n",
              "      <td>21.561703</td>\n",
              "      <td>21.515179</td>\n",
              "      <td>21.827815</td>\n",
              "      <td>...</td>\n",
              "      <td>11.430807</td>\n",
              "      <td>17.473703</td>\n",
              "      <td>17.600155</td>\n",
              "      <td>19.374428</td>\n",
              "      <td>19.211887</td>\n",
              "      <td>18.464396</td>\n",
              "      <td>17.701903</td>\n",
              "      <td>15.871735</td>\n",
              "      <td>17.710839</td>\n",
              "      <td>0.239559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>155.00000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>176.00000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>181.00000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>186.00000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>207.00000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Height        Weight           Age     Weak_foot   Skill_Moves  \\\n",
              "count  17588.00000  17588.000000  17588.000000  17588.000000  17588.000000   \n",
              "mean     181.10547     75.253355     25.460314      2.934103      2.303161   \n",
              "std        6.67516      6.897948      4.680217      0.655927      0.746156   \n",
              "min      155.00000     48.000000     17.000000      1.000000      1.000000   \n",
              "25%      176.00000     70.000000     22.000000      3.000000      2.000000   \n",
              "50%      181.00000     75.000000     25.000000      3.000000      2.000000   \n",
              "75%      186.00000     80.000000     29.000000      3.000000      3.000000   \n",
              "max      207.00000    110.000000     47.000000      5.000000      5.000000   \n",
              "\n",
              "       Ball_Control     Dribbling       Marking  Sliding_Tackle  \\\n",
              "count  17588.000000  17588.000000  17588.000000    17588.000000   \n",
              "mean      57.972766     54.802877     44.230327       45.565499   \n",
              "std       16.834779     18.913857     21.561703       21.515179   \n",
              "min        5.000000      4.000000      3.000000        5.000000   \n",
              "25%       53.000000     47.000000     22.000000       23.000000   \n",
              "50%       63.000000     60.000000     48.000000       51.000000   \n",
              "75%       69.000000     68.000000     64.000000       64.000000   \n",
              "max       95.000000     97.000000     92.000000       95.000000   \n",
              "\n",
              "       Standing_Tackle  ...       Jumping       Heading    Shot_Power  \\\n",
              "count     17588.000000  ...  17588.000000  17588.000000  17588.000000   \n",
              "mean         47.441096  ...     64.918524     52.393109     55.581192   \n",
              "std          21.827815  ...     11.430807     17.473703     17.600155   \n",
              "min           3.000000  ...     15.000000      4.000000      3.000000   \n",
              "25%          26.000000  ...     58.000000     45.000000     45.000000   \n",
              "50%          54.000000  ...     65.000000     56.000000     59.000000   \n",
              "75%          66.000000  ...     73.000000     65.000000     69.000000   \n",
              "max          92.000000  ...     95.000000     94.000000     93.000000   \n",
              "\n",
              "          Finishing    Long_Shots         Curve  Freekick_Accuracy  \\\n",
              "count  17588.000000  17588.000000  17588.000000       17588.000000   \n",
              "mean      45.157607     47.403173     47.181146          43.383443   \n",
              "std       19.374428     19.211887     18.464396          17.701903   \n",
              "min        2.000000      4.000000      6.000000           4.000000   \n",
              "25%       29.000000     32.000000     34.000000          31.000000   \n",
              "50%       48.000000     52.000000     48.000000          42.000000   \n",
              "75%       61.000000     63.000000     62.000000          57.000000   \n",
              "max       95.000000     91.000000     92.000000          93.000000   \n",
              "\n",
              "          Penalties       Volleys         label  \n",
              "count  17588.000000  17588.000000  17588.000000  \n",
              "mean      49.165738     43.275586      0.061121  \n",
              "std       15.871735     17.710839      0.239559  \n",
              "min        7.000000      3.000000      0.000000  \n",
              "25%       39.000000     30.000000      0.000000  \n",
              "50%       50.000000     44.000000      0.000000  \n",
              "75%       61.000000     57.000000      0.000000  \n",
              "max       96.000000     93.000000      1.000000  \n",
              "\n",
              "[8 rows x 34 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ahora generaremos una descripción para cada columna numérica\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Name                 17341\n",
              "Nationality            160\n",
              "National_Position       27\n",
              "Club_Position           29\n",
              "Height                  50\n",
              "Weight                  56\n",
              "Preffered_Foot           2\n",
              "Age                     29\n",
              "Work_Rate                9\n",
              "Weak_foot                5\n",
              "Skill_Moves              5\n",
              "Ball_Control            88\n",
              "Dribbling               92\n",
              "Marking                 89\n",
              "Sliding_Tackle          88\n",
              "Standing_Tackle         89\n",
              "Aggression              88\n",
              "Reactions               67\n",
              "Interceptions           90\n",
              "Vision                  85\n",
              "Composure               85\n",
              "Crossing                85\n",
              "Short_Pass              83\n",
              "Long_Pass               85\n",
              "Acceleration            86\n",
              "Speed                   85\n",
              "Stamina                 86\n",
              "Strength                77\n",
              "Balance                 86\n",
              "Agility                 83\n",
              "Jumping                 74\n",
              "Heading                 90\n",
              "Shot_Power              88\n",
              "Finishing               94\n",
              "Long_Shots              88\n",
              "Curve                   87\n",
              "Freekick_Accuracy       87\n",
              "Penalties               86\n",
              "Volleys                 90\n",
              "label                    2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Veamos la cantidad de valores únicos por columna\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tenemos diferentes tipos de datos en este dataset, existiendo características numéricas que tienen poca variación (por ejemplo `National_Positions`) y otras con bastante variación (`Dribbling`, `Aggression`, entre otras), además de variables de tipo *string* que pueden tener muchos o pocos valores. En resumen, tenemos los siguientes tipos de categorías:\n",
        "\n",
        "1. **Variables Numéricas**: `Height`, `Weight`, `Age`, `Ball_Control`, `Dribbling`, `Marking`, `Sliding_Tackle`, `Standing_Tackle`, `Aggression`, `Reactions`, `Interceptions`, `Vision`, `Composure`, `Crossing`, `Short_Pass`, `Long_Pass`, `Acceleration`, `Speed`, `Stamina`, `Strength`, `Balance`, `Agility`, `Jumping`, `Heading`, `Shot_Power`, `Finishing`, `Long_Shots`, `Curve`, `Freekick_Accuracy`, `Penalties`, `Volleys`.\n",
        "2. **Variables Categóricas**: `Nationality`, `National_Position`, `Club_Position`, `Preffered_Foot`, `Work_Rate`, `Weak_foot`, `Skill_Moves`.\n",
        "3. **Variables tipo string**: `Name`.\n",
        "\n",
        "Esto nos lleva a pensar de que podemos hacer las siguientes transformaciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformar las variables numéricas tipo calificación con MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "num_cal_columns = ['Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle', 'Standing_Tackle',\n",
        "               'Aggression', 'Reactions', 'Interceptions', 'Vision', 'Composure', 'Crossing', 'Short_Pass', 'Long_Pass',\n",
        "               'Acceleration', 'Speed', 'Stamina', 'Strength', 'Balance', 'Agility', 'Jumping', 'Heading', 'Shot_Power',\n",
        "               'Finishing', 'Long_Shots', 'Curve', 'Freekick_Accuracy', 'Penalties', 'Volleys']\n",
        "num_cal_scaler = MinMaxScaler()\n",
        "\n",
        "# Transformar las variables numéricas restantes (altura, peso y edad) con StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_oth_columns = ['Height', 'Weight', 'Age']\n",
        "num_oth_scaler = StandardScaler()\n",
        "\n",
        "# Transformar las variables categóricas con OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_columns = ['Nationality', 'National_Position', 'Club_Position', 'Preffered_Foot', 'Work_Rate', 'Weak_foot', 'Skill_Moves']\n",
        "cat_encoder = OneHotEncoder()\n",
        "\n",
        "# Crear un ColumnTransformer para aplicar las transformaciones a las columnas correspondientes\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "col_transformer = ColumnTransformer([\n",
        "    ('num', num_cal_scaler, num_cal_columns),\n",
        "    ('num_oth', num_oth_scaler, num_oth_columns),\n",
        "    ('cat', cat_encoder, cat_columns)\n",
        "],\n",
        "    remainder='passthrough')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Justificación\n",
        "\n",
        "Estas transformaciones se realizan por las siguientes razones:\n",
        "\n",
        "* Dentro de las variables numéricas existen $3$ que podríamos considerar como una excepción a la generalización que se va a explicar: `Height`, `Weight` y `Age`. El resto de variables (`Dribbling`, `Aggression`, etc.) son una calificación que se le da al jugador entre $1$ y $100$ (aunque no existen jugadores con alguna marca perfecta). Todas estas variables numéricas las podemos normalizar entre $0$ y $1$ ya que no chocan entre ellas usando `MinMaxScaler`.\n",
        "\n",
        "* Las variables `Height`, `Weight` y `Age` no se rankean entre $1$ y $100$ y no significan un \"más alto es mejor\". De todas formas se deben escalar a valores entre $0$ y $1$, pero de manera independiente usando `StandardScaler`.\n",
        "\n",
        "* Las variables categóricas justamente categorizan a los jugadores según procedencia y otros aspectos más cualitativos, además de existir variables de tipo `string` (nacionalidades y posiciones). Las variables cuantitativas siguen siendo una categorización con un orden específico. Para todas estas se usa una transformación tipo `OneHotEncoder`.\n",
        "\n",
        "Además, no trabajaremos con el nombre del jugador, ya que es una variable para simplemente identificar la observación que  **no debe influir** en el funcionamiento del algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporción queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribución original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentación de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la sección de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Separación de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lLtlXGTPdWAV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = df.drop(columns = ['Name'])\n",
        "labels = df.loc[:, 'label']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.33, shuffle=True, stratify=labels, random_state=30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    0.938895\n",
            "1    0.061105\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "label\n",
            "0    0.938846\n",
            "1    0.061154\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Revisar la distribución de etiquetas en los conjuntos de entrenamiento y prueba\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print('')\n",
        "print(y_test.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Definición de *pipeline*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Definición de pipeline para entrenamiento con XGBoost\n",
        "xgb_model = XGBClassifier()\n",
        "pipeline_xgboost = Pipeline([\n",
        "    ('preprocessor', col_transformer),\n",
        "    ('classifier', xgb_model)\n",
        "])\n",
        "\n",
        "# Definición de pipeline para entrenamiento con LightGBM\n",
        "lgb_model = LGBMClassifier()\n",
        "pipeline_lightgbm = Pipeline([\n",
        "    ('preprocessor', col_transformer),\n",
        "    ('classifier', lgb_model)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Entrenamiento del *pipeline*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m pipeline_xgboost\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Revisión de desempeño de XGBoost\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y_pred_xgboost \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_xgboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_xgboost))\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1076\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1076\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         )\n\u001b[1;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:1290\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1290\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1024\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1023\u001b[0m }\n\u001b[1;32m-> 1024\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:214\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    210\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
            "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform"
          ]
        }
      ],
      "source": [
        "# Entrenamiento de XGBoost\n",
        "pipeline_xgboost.fit(X_train, y_train)\n",
        "\n",
        "# Revisión de desempeño de XGBoost\n",
        "y_pred_xgboost = pipeline_xgboost.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_xgboost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 720, number of negative: 11063\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2665\n",
            "[LightGBM] [Info] Number of data points in the train set: 11783, number of used features: 154\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061105 -> initscore=-2.732110\n",
            "[LightGBM] [Info] Start training from score -2.732110\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m pipeline_lightgbm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Revisión de desempeño de LightGBM\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y_pred_lightgbm \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_lightgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_lightgbm))\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1076\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1076\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         )\n\u001b[1;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:1290\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1290\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1024\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1023\u001b[0m }\n\u001b[1;32m-> 1024\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:214\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    210\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
            "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform"
          ]
        }
      ],
      "source": [
        "# Entrenamiento de LightGBM\n",
        "pipeline_lightgbm.fit(X_train, y_train)\n",
        "\n",
        "# Revisión de desempeño de LightGBM\n",
        "y_pred_lightgbm = pipeline_lightgbm.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_lightgbm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las métricas accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qué implican los valores de accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y cómo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qué métrica le parece más adecuada y concluya qué modelo tiene un mejor desempeño. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Cálculo de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNmI_tbbdQte"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicción de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renacín escuchó a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posición en la cancha en la que juega. Y además, que hay bastantes jugadores nuevos que no tienen muy claro en que posición verdaderamente brillarían, por lo que actualmente puede que actualmente estén jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer análisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posición de los jugadores en la cancha según sus características.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renacín les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elección del clasificador se justificar en base a la siguiente [guía](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificación.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores señalados en esta sección y guárdelos en la variable `label`.\n",
        "2. Cuente cuántos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluación de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir_7zMh2i1vg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Después de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el fútbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teoría es que muchos artistas del género urbano chileno, con sus habilidades únicas y su disciplina, podrían destacarse también en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino también demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 3.1 ¿Qué modelo de árbol es más de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la sección 1.1. Para determinar cuál modelo de árbol sería más adecuado para la tarea en cuestión, utilice PyCaret. Este deberá centrarse exclusivamente en modelos de tipo árbol. Jere ha especificado que busca un modelo que tome decisiones rápidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos] \n",
        "\n",
        "Para la comparación, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "3. Tras realizar la comparación de modelos, seleccione aquel que muestre el mejor rendimiento en términos de velocidad y precisión, especialmente en la reducción de falsos positivos. Utilice la función `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusión Matrix**: ¿Cómo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: ¿Es acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: ¿Cuáles son las variables con mejor desempeño? ¿A qué podría deberse esto?\n",
        "  - **Learning Curve**: ¿El modelo presenta algún problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUCjOjsEYUXL"
      },
      "outputs": [],
      "source": [
        "from pycaret.datasets import get_data\n",
        "from pycaret.classification import *\n",
        "import os\n",
        "\n",
        "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
        "\n",
        "#Continuar código aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 3.2 Reducción de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Además, se debe proceder a realizar una reducción de dimensionalidad basada en la importancia de las características.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las características disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo esté entrenado, evalúe y clasifique las características según su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificación para ejecutar una búsqueda recursiva de eliminación de características, eliminando progresivamente las menos importantes y evaluando el impacto en el desempeño del modelo hasta identificar las N características más críticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de características, entrene un nuevo modelo y evalúe su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensión más profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¿El rendimiento del modelo con las características seleccionadas es similar al del modelo original? ¿Cómo se comparan en términos de precisión y robustez? [2 puntos]\n",
        "  - ¿Cuáles son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificación del modelo, reducción del tiempo de entrenamiento, y mejora en la capacidad de generalización. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es más sencillo de explicar. Explique brevemente por qué la eliminación de ciertas características puede facilitar la comprensión y la explicación del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre número de festures y desempeño. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar más features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwUd_nsuDOe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 3.3 Calibración Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos más modulares, se recomienda realizar una calibración del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un método de calibración que asegure que las probabilidades generadas incrementen de manera monótona. Una métrica ampliamente utilizada para evaluar la precisión de la calibración de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como después de la calibración. Esto le permitirá realizar una comparación cuantitativa y determinar si la calibración ha mejorado el rendimiento del modelo. Para más información sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibración, examine y comente los resultados obtenidos. A su análisis añada una comparación visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k-ao0mOU64Ru",
        "Jg_9jBqtgRDO",
        "JdcucZhp-M_0",
        "Qfre1YsSDqla",
        "Bv1HOfcNEPF4",
        "poc9HSNBFeKO",
        "uy5VMU6ae_g6",
        "9bL2m8nNojXM",
        "rD8pQ5Zfq8dE",
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
