{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 7: Clasificaci贸n \n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci贸n Cient铆fica para Ciencia de Datos - Primavera 2024</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti谩n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol谩s Ojeda, Melanie Pe帽a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser谩n revisados\n",
        "\n",
        "- Nombre de alumno 1:\n",
        "- Nombre de alumno 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/...../)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificaci贸n en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser谩n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C贸digo que no se pueda ejecutar, no ser谩 revisado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c贸mo trabajar con problemas de clasificaci贸n con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Te贸rica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cu谩l es la diferencia entre los datos de entrenamiento y validaci贸n. [1 punto]\n",
        "\n",
        "2. Explique cu谩l es el principal desaf铆o al trabajar problemas de clasificaci贸n con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qu茅 es la matriz de confusi贸n y para qu茅 se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la f贸rmula de las siguientes m茅tricas y explique con **sus palabras** c贸mo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qu茅 m茅trica recomendar铆a para los siguientes contextos de clasificaci贸n. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detecci贸n de enfermedades altamente contagiosas.\n",
        "  * Aprobaci贸n de cr茅ditos de alto riesgo.\n",
        "  * Detecci贸n de cr铆menes.\n",
        "\n",
        "6. Explique qu茅 es la calibraci贸n de modelos y para qu茅 se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "*Escriba su respuesta aqu铆*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte pr谩ctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/61L8z0w/renacin-by-volframio-dcirf4l-fullview.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "Tras el tr谩gico despido de la m铆tica mascota de Maip煤, Renac铆n decide adentrarse como consultor en el mercado futbolero, el cu谩l (para variar...) est谩 cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea ser谩 asesorar a los directivos de los clubes sobre cu谩l jugador comprar y cu谩l no, Renac铆n desea generar modelos predictivos que evalu茅n distintas caracter铆sticas de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condici贸n de corporeo le impidi贸 tomar la versi贸n anterior de MDS7202, por lo que este motivo Renac铆n contrata a su equipo para lograr su objetivo final. Dado que a煤n tiene fuertes v铆nculos con la direcci贸n de deportes de la municipalidad, el corporeo le entrega base de datos con las estad铆sticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deber谩n trabajar con el csv `statsplayers.csv`, donde deber谩n aplicar algoritmos de aprendizaje supervisado de clasificaci贸n en base a caracter铆sticas que describen de jugadores de f煤tbol.\n",
        "\n",
        "Para comenzar cargue el dataset se帽alado y a continuaci贸n vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las caracter铆sticas principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mX6iwOWUfrp_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexi贸n drive-colab\n"
          ]
        }
      ],
      "source": [
        "# Si usted est谩 utilizando Colabolatory le puede ser 煤til este c贸digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = 'Direcci贸n donde tiene los archivos en el Drive'\n",
        "except:\n",
        "    print('Ignorando conexi贸n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicci贸n de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificaci贸n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa铆s. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, 驴cu谩ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu谩rdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Generaci贸n de *labels*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JhC2sZj9dSI1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>National_Position</th>\n",
              "      <th>Club_Position</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Preffered_Foot</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Rate</th>\n",
              "      <th>Weak_foot</th>\n",
              "      <th>...</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Shot_Power</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>Long_Shots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>Freekick_Accuracy</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>LS</td>\n",
              "      <td>LW</td>\n",
              "      <td>185</td>\n",
              "      <td>80</td>\n",
              "      <td>Right</td>\n",
              "      <td>32</td>\n",
              "      <td>High / Low</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>85</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>90</td>\n",
              "      <td>81</td>\n",
              "      <td>76</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>RW</td>\n",
              "      <td>RW</td>\n",
              "      <td>170</td>\n",
              "      <td>72</td>\n",
              "      <td>Left</td>\n",
              "      <td>29</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>85</td>\n",
              "      <td>95</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>74</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Neymar</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>LW</td>\n",
              "      <td>LW</td>\n",
              "      <td>174</td>\n",
              "      <td>68</td>\n",
              "      <td>Right</td>\n",
              "      <td>25</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>61</td>\n",
              "      <td>62</td>\n",
              "      <td>78</td>\n",
              "      <td>89</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>84</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Luis Su谩rez</td>\n",
              "      <td>Uruguay</td>\n",
              "      <td>LS</td>\n",
              "      <td>ST</td>\n",
              "      <td>182</td>\n",
              "      <td>85</td>\n",
              "      <td>Right</td>\n",
              "      <td>30</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>69</td>\n",
              "      <td>77</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manuel Neuer</td>\n",
              "      <td>Germany</td>\n",
              "      <td>GK</td>\n",
              "      <td>GK</td>\n",
              "      <td>193</td>\n",
              "      <td>92</td>\n",
              "      <td>Right</td>\n",
              "      <td>31</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name Nationality National_Position Club_Position  Height  \\\n",
              "0  Cristiano Ronaldo    Portugal                LS            LW     185   \n",
              "1       Lionel Messi   Argentina                RW            RW     170   \n",
              "2             Neymar      Brazil                LW            LW     174   \n",
              "3        Luis Su谩rez     Uruguay                LS            ST     182   \n",
              "4       Manuel Neuer     Germany                GK            GK     193   \n",
              "\n",
              "   Weight Preffered_Foot  Age        Work_Rate  Weak_foot  ...  Agility  \\\n",
              "0      80          Right   32       High / Low          4  ...       90   \n",
              "1      72           Left   29  Medium / Medium          4  ...       90   \n",
              "2      68          Right   25    High / Medium          5  ...       96   \n",
              "3      85          Right   30    High / Medium          4  ...       86   \n",
              "4      92          Right   31  Medium / Medium          4  ...       52   \n",
              "\n",
              "   Jumping  Heading  Shot_Power  Finishing  Long_Shots  Curve  \\\n",
              "0       95       85          92         93          90     81   \n",
              "1       68       71          85         95          88     89   \n",
              "2       61       62          78         89          77     79   \n",
              "3       69       77          87         94          86     86   \n",
              "4       78       25          25         13          16     14   \n",
              "\n",
              "   Freekick_Accuracy  Penalties  Volleys  \n",
              "0                 76         85       88  \n",
              "1                 90         74       85  \n",
              "2                 84         81       83  \n",
              "3                 84         85       88  \n",
              "4                 11         47       11  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('stats_players.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generaci贸n de columna 'label' en base a columna 'National_Position'\n",
        "df['label'] = df['National_Position'].apply(lambda x: 1 if pd.notnull(x) else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Conteo de clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    16513\n",
              "1     1075\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se puede ver, existen $16.513$ jugadores que no poseen una posici贸n definida en su selecci贸n nacional, habiendo en cambio $1.075$ que s铆 tienen una posici贸n en la selecci贸n nacional de su pa铆s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Generaci贸n de `ColumnTransformer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Name                 object\n",
              "Nationality          object\n",
              "National_Position    object\n",
              "Club_Position        object\n",
              "Height                int64\n",
              "Weight                int64\n",
              "Preffered_Foot       object\n",
              "Age                   int64\n",
              "Work_Rate            object\n",
              "Weak_foot             int64\n",
              "Skill_Moves           int64\n",
              "Ball_Control          int64\n",
              "Dribbling             int64\n",
              "Marking               int64\n",
              "Sliding_Tackle        int64\n",
              "Standing_Tackle       int64\n",
              "Aggression            int64\n",
              "Reactions             int64\n",
              "Interceptions         int64\n",
              "Vision                int64\n",
              "Composure             int64\n",
              "Crossing              int64\n",
              "Short_Pass            int64\n",
              "Long_Pass             int64\n",
              "Acceleration          int64\n",
              "Speed                 int64\n",
              "Stamina               int64\n",
              "Strength              int64\n",
              "Balance               int64\n",
              "Agility               int64\n",
              "Jumping               int64\n",
              "Heading               int64\n",
              "Shot_Power            int64\n",
              "Finishing             int64\n",
              "Long_Shots            int64\n",
              "Curve                 int64\n",
              "Freekick_Accuracy     int64\n",
              "Penalties             int64\n",
              "Volleys               int64\n",
              "label                 int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Primero veremos el tipo de dato en cada columna.\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Age</th>\n",
              "      <th>Weak_foot</th>\n",
              "      <th>Skill_Moves</th>\n",
              "      <th>Ball_Control</th>\n",
              "      <th>Dribbling</th>\n",
              "      <th>Marking</th>\n",
              "      <th>Sliding_Tackle</th>\n",
              "      <th>Standing_Tackle</th>\n",
              "      <th>...</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Shot_Power</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>Long_Shots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>Freekick_Accuracy</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17588.00000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "      <td>17588.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>181.10547</td>\n",
              "      <td>75.253355</td>\n",
              "      <td>25.460314</td>\n",
              "      <td>2.934103</td>\n",
              "      <td>2.303161</td>\n",
              "      <td>57.972766</td>\n",
              "      <td>54.802877</td>\n",
              "      <td>44.230327</td>\n",
              "      <td>45.565499</td>\n",
              "      <td>47.441096</td>\n",
              "      <td>...</td>\n",
              "      <td>64.918524</td>\n",
              "      <td>52.393109</td>\n",
              "      <td>55.581192</td>\n",
              "      <td>45.157607</td>\n",
              "      <td>47.403173</td>\n",
              "      <td>47.181146</td>\n",
              "      <td>43.383443</td>\n",
              "      <td>49.165738</td>\n",
              "      <td>43.275586</td>\n",
              "      <td>0.061121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.67516</td>\n",
              "      <td>6.897948</td>\n",
              "      <td>4.680217</td>\n",
              "      <td>0.655927</td>\n",
              "      <td>0.746156</td>\n",
              "      <td>16.834779</td>\n",
              "      <td>18.913857</td>\n",
              "      <td>21.561703</td>\n",
              "      <td>21.515179</td>\n",
              "      <td>21.827815</td>\n",
              "      <td>...</td>\n",
              "      <td>11.430807</td>\n",
              "      <td>17.473703</td>\n",
              "      <td>17.600155</td>\n",
              "      <td>19.374428</td>\n",
              "      <td>19.211887</td>\n",
              "      <td>18.464396</td>\n",
              "      <td>17.701903</td>\n",
              "      <td>15.871735</td>\n",
              "      <td>17.710839</td>\n",
              "      <td>0.239559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>155.00000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>176.00000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>181.00000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>186.00000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>207.00000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Height        Weight           Age     Weak_foot   Skill_Moves  \\\n",
              "count  17588.00000  17588.000000  17588.000000  17588.000000  17588.000000   \n",
              "mean     181.10547     75.253355     25.460314      2.934103      2.303161   \n",
              "std        6.67516      6.897948      4.680217      0.655927      0.746156   \n",
              "min      155.00000     48.000000     17.000000      1.000000      1.000000   \n",
              "25%      176.00000     70.000000     22.000000      3.000000      2.000000   \n",
              "50%      181.00000     75.000000     25.000000      3.000000      2.000000   \n",
              "75%      186.00000     80.000000     29.000000      3.000000      3.000000   \n",
              "max      207.00000    110.000000     47.000000      5.000000      5.000000   \n",
              "\n",
              "       Ball_Control     Dribbling       Marking  Sliding_Tackle  \\\n",
              "count  17588.000000  17588.000000  17588.000000    17588.000000   \n",
              "mean      57.972766     54.802877     44.230327       45.565499   \n",
              "std       16.834779     18.913857     21.561703       21.515179   \n",
              "min        5.000000      4.000000      3.000000        5.000000   \n",
              "25%       53.000000     47.000000     22.000000       23.000000   \n",
              "50%       63.000000     60.000000     48.000000       51.000000   \n",
              "75%       69.000000     68.000000     64.000000       64.000000   \n",
              "max       95.000000     97.000000     92.000000       95.000000   \n",
              "\n",
              "       Standing_Tackle  ...       Jumping       Heading    Shot_Power  \\\n",
              "count     17588.000000  ...  17588.000000  17588.000000  17588.000000   \n",
              "mean         47.441096  ...     64.918524     52.393109     55.581192   \n",
              "std          21.827815  ...     11.430807     17.473703     17.600155   \n",
              "min           3.000000  ...     15.000000      4.000000      3.000000   \n",
              "25%          26.000000  ...     58.000000     45.000000     45.000000   \n",
              "50%          54.000000  ...     65.000000     56.000000     59.000000   \n",
              "75%          66.000000  ...     73.000000     65.000000     69.000000   \n",
              "max          92.000000  ...     95.000000     94.000000     93.000000   \n",
              "\n",
              "          Finishing    Long_Shots         Curve  Freekick_Accuracy  \\\n",
              "count  17588.000000  17588.000000  17588.000000       17588.000000   \n",
              "mean      45.157607     47.403173     47.181146          43.383443   \n",
              "std       19.374428     19.211887     18.464396          17.701903   \n",
              "min        2.000000      4.000000      6.000000           4.000000   \n",
              "25%       29.000000     32.000000     34.000000          31.000000   \n",
              "50%       48.000000     52.000000     48.000000          42.000000   \n",
              "75%       61.000000     63.000000     62.000000          57.000000   \n",
              "max       95.000000     91.000000     92.000000          93.000000   \n",
              "\n",
              "          Penalties       Volleys         label  \n",
              "count  17588.000000  17588.000000  17588.000000  \n",
              "mean      49.165738     43.275586      0.061121  \n",
              "std       15.871735     17.710839      0.239559  \n",
              "min        7.000000      3.000000      0.000000  \n",
              "25%       39.000000     30.000000      0.000000  \n",
              "50%       50.000000     44.000000      0.000000  \n",
              "75%       61.000000     57.000000      0.000000  \n",
              "max       96.000000     93.000000      1.000000  \n",
              "\n",
              "[8 rows x 34 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ahora generaremos una descripci贸n para cada columna num茅rica\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Name                 17341\n",
              "Nationality            160\n",
              "National_Position       27\n",
              "Club_Position           29\n",
              "Height                  50\n",
              "Weight                  56\n",
              "Preffered_Foot           2\n",
              "Age                     29\n",
              "Work_Rate                9\n",
              "Weak_foot                5\n",
              "Skill_Moves              5\n",
              "Ball_Control            88\n",
              "Dribbling               92\n",
              "Marking                 89\n",
              "Sliding_Tackle          88\n",
              "Standing_Tackle         89\n",
              "Aggression              88\n",
              "Reactions               67\n",
              "Interceptions           90\n",
              "Vision                  85\n",
              "Composure               85\n",
              "Crossing                85\n",
              "Short_Pass              83\n",
              "Long_Pass               85\n",
              "Acceleration            86\n",
              "Speed                   85\n",
              "Stamina                 86\n",
              "Strength                77\n",
              "Balance                 86\n",
              "Agility                 83\n",
              "Jumping                 74\n",
              "Heading                 90\n",
              "Shot_Power              88\n",
              "Finishing               94\n",
              "Long_Shots              88\n",
              "Curve                   87\n",
              "Freekick_Accuracy       87\n",
              "Penalties               86\n",
              "Volleys                 90\n",
              "label                    2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Veamos la cantidad de valores 煤nicos por columna\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tenemos diferentes tipos de datos en este dataset, existiendo caracter铆sticas num茅ricas que tienen poca variaci贸n (por ejemplo `National_Positions`) y otras con bastante variaci贸n (`Dribbling`, `Aggression`, entre otras), adem谩s de variables de tipo *string* que pueden tener muchos o pocos valores. En resumen, tenemos los siguientes tipos de categor铆as:\n",
        "\n",
        "1. **Variables Num茅ricas**: `Height`, `Weight`, `Age`, `Ball_Control`, `Dribbling`, `Marking`, `Sliding_Tackle`, `Standing_Tackle`, `Aggression`, `Reactions`, `Interceptions`, `Vision`, `Composure`, `Crossing`, `Short_Pass`, `Long_Pass`, `Acceleration`, `Speed`, `Stamina`, `Strength`, `Balance`, `Agility`, `Jumping`, `Heading`, `Shot_Power`, `Finishing`, `Long_Shots`, `Curve`, `Freekick_Accuracy`, `Penalties`, `Volleys`.\n",
        "2. **Variables Categ贸ricas**: `Nationality`, `National_Position`, `Club_Position`, `Preffered_Foot`, `Work_Rate`, `Weak_foot`, `Skill_Moves`.\n",
        "3. **Variables tipo string**: `Name`.\n",
        "\n",
        "Esto nos lleva a pensar de que podemos hacer las siguientes transformaciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformar las variables num茅ricas tipo calificaci贸n con MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "num_cal_columns = ['Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle', 'Standing_Tackle',\n",
        "               'Aggression', 'Reactions', 'Interceptions', 'Vision', 'Composure', 'Crossing', 'Short_Pass', 'Long_Pass',\n",
        "               'Acceleration', 'Speed', 'Stamina', 'Strength', 'Balance', 'Agility', 'Jumping', 'Heading', 'Shot_Power',\n",
        "               'Finishing', 'Long_Shots', 'Curve', 'Freekick_Accuracy', 'Penalties', 'Volleys']\n",
        "num_cal_scaler = MinMaxScaler()\n",
        "\n",
        "# Transformar las variables num茅ricas restantes (altura, peso y edad) con StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_oth_columns = ['Height', 'Weight', 'Age']\n",
        "num_oth_scaler = StandardScaler()\n",
        "\n",
        "# Transformar las variables categ贸ricas con OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_columns = ['Nationality', 'National_Position', 'Club_Position', 'Preffered_Foot', 'Work_Rate', 'Weak_foot', 'Skill_Moves']\n",
        "cat_encoder = OneHotEncoder()\n",
        "\n",
        "# Crear un ColumnTransformer para aplicar las transformaciones a las columnas correspondientes\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "col_transformer = ColumnTransformer([\n",
        "    ('num', num_cal_scaler, num_cal_columns),\n",
        "    ('num_oth', num_oth_scaler, num_oth_columns),\n",
        "    ('cat', cat_encoder, cat_columns)\n",
        "],\n",
        "    remainder='passthrough')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Justificaci贸n\n",
        "\n",
        "Estas transformaciones se realizan por las siguientes razones:\n",
        "\n",
        "* Dentro de las variables num茅ricas existen $3$ que podr铆amos considerar como una excepci贸n a la generalizaci贸n que se va a explicar: `Height`, `Weight` y `Age`. El resto de variables (`Dribbling`, `Aggression`, etc.) son una calificaci贸n que se le da al jugador entre $1$ y $100$ (aunque no existen jugadores con alguna marca perfecta). Todas estas variables num茅ricas las podemos normalizar entre $0$ y $1$ ya que no chocan entre ellas usando `MinMaxScaler`.\n",
        "\n",
        "* Las variables `Height`, `Weight` y `Age` no se rankean entre $1$ y $100$ y no significan un \"m谩s alto es mejor\". De todas formas se deben escalar a valores entre $0$ y $1$, pero de manera independiente usando `StandardScaler`.\n",
        "\n",
        "* Las variables categ贸ricas justamente categorizan a los jugadores seg煤n procedencia y otros aspectos m谩s cualitativos, adem谩s de existir variables de tipo `string` (nacionalidades y posiciones). Las variables cuantitativas siguen siendo una categorizaci贸n con un orden espec铆fico. Para todas estas se usa una transformaci贸n tipo `OneHotEncoder`.\n",
        "\n",
        "Adem谩s, no trabajaremos con el nombre del jugador, ya que es una variable para simplemente identificar la observaci贸n que  **no debe influir** en el funcionamiento del algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporci贸n queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribuci贸n original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentaci贸n de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la secci贸n de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Separaci贸n de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lLtlXGTPdWAV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = df.drop(columns = ['Name'])\n",
        "labels = df.loc[:, 'label']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.33, shuffle=True, stratify=labels, random_state=30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    0.938895\n",
            "1    0.061105\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "label\n",
            "0    0.938846\n",
            "1    0.061154\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Revisar la distribuci贸n de etiquetas en los conjuntos de entrenamiento y prueba\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print('')\n",
        "print(y_test.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Definici贸n de *pipeline*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Definici贸n de pipeline para entrenamiento con XGBoost\n",
        "xgb_model = XGBClassifier()\n",
        "pipeline_xgboost = Pipeline([\n",
        "    ('preprocessor', col_transformer),\n",
        "    ('classifier', xgb_model)\n",
        "])\n",
        "\n",
        "# Definici贸n de pipeline para entrenamiento con LightGBM\n",
        "lgb_model = LGBMClassifier()\n",
        "pipeline_lightgbm = Pipeline([\n",
        "    ('preprocessor', col_transformer),\n",
        "    ('classifier', lgb_model)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Entrenamiento del *pipeline*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m pipeline_xgboost\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Revisi贸n de desempe帽o de XGBoost\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y_pred_xgboost \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_xgboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_xgboost))\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1076\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1076\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         )\n\u001b[1;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:1290\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1290\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1024\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1023\u001b[0m }\n\u001b[1;32m-> 1024\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:214\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    210\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
            "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform"
          ]
        }
      ],
      "source": [
        "# Entrenamiento de XGBoost\n",
        "pipeline_xgboost.fit(X_train, y_train)\n",
        "\n",
        "# Revisi贸n de desempe帽o de XGBoost\n",
        "y_pred_xgboost = pipeline_xgboost.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_xgboost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 720, number of negative: 11063\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2665\n",
            "[LightGBM] [Info] Number of data points in the train set: 11783, number of used features: 154\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061105 -> initscore=-2.732110\n",
            "[LightGBM] [Info] Start training from score -2.732110\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m pipeline_lightgbm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Revisi贸n de desempe帽o de LightGBM\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y_pred_lightgbm \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_lightgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_lightgbm))\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1076\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1076\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         )\n\u001b[1;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:1290\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1290\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1024\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1023\u001b[0m }\n\u001b[1;32m-> 1024\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:214\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    210\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
            "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Eritrea', 'Barbados', 'Aruba', 'Lesotho', 'Namibia', 'Fiji'] in column 0 during transform"
          ]
        }
      ],
      "source": [
        "# Entrenamiento de LightGBM\n",
        "pipeline_lightgbm.fit(X_train, y_train)\n",
        "\n",
        "# Revisi贸n de desempe帽o de LightGBM\n",
        "y_pred_lightgbm = pipeline_lightgbm.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_lightgbm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las m茅tricas accuracy, precisi贸n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qu茅 implican los valores de accuracy, precisi贸n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c贸mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qu茅 m茅trica le parece m谩s adecuada y concluya qu茅 modelo tiene un mejor desempe帽o. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. C谩lculo de m茅tricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNmI_tbbdQte"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicci贸n de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renac铆n escuch贸 a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posici贸n en la cancha en la que juega. Y adem谩s, que hay bastantes jugadores nuevos que no tienen muy claro en que posici贸n verdaderamente brillar铆an, por lo que actualmente puede que actualmente est茅n jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer an谩lisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posici贸n de los jugadores en la cancha seg煤n sus caracter铆sticas.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renac铆n les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elecci贸n del clasificador se justificar en base a la siguiente [gu铆a](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificaci贸n.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores se帽alados en esta secci贸n y gu谩rdelos en la variable `label`.\n",
        "2. Cuente cu谩ntos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluaci贸n de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir_7zMh2i1vg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Despu茅s de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el f煤tbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teor铆a es que muchos artistas del g茅nero urbano chileno, con sus habilidades 煤nicas y su disciplina, podr铆an destacarse tambi茅n en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino tambi茅n demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 3.1 驴Qu茅 modelo de 谩rbol es m谩s de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la secci贸n 1.1. Para determinar cu谩l modelo de 谩rbol ser铆a m谩s adecuado para la tarea en cuesti贸n, utilice PyCaret. Este deber谩 centrarse exclusivamente en modelos de tipo 谩rbol. Jere ha especificado que busca un modelo que tome decisiones r谩pidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos] \n",
        "\n",
        "Para la comparaci贸n, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "3. Tras realizar la comparaci贸n de modelos, seleccione aquel que muestre el mejor rendimiento en t茅rminos de velocidad y precisi贸n, especialmente en la reducci贸n de falsos positivos. Utilice la funci贸n `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusi贸n Matrix**: 驴C贸mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: 驴Es acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: 驴Cu谩les son las variables con mejor desempe帽o? 驴A qu茅 podr铆a deberse esto?\n",
        "  - **Learning Curve**: 驴El modelo presenta alg煤n problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUCjOjsEYUXL"
      },
      "outputs": [],
      "source": [
        "from pycaret.datasets import get_data\n",
        "from pycaret.classification import *\n",
        "import os\n",
        "\n",
        "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
        "\n",
        "#Continuar c贸digo aqu铆"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 3.2 Reducci贸n de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Adem谩s, se debe proceder a realizar una reducci贸n de dimensionalidad basada en la importancia de las caracter铆sticas.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las caracter铆sticas disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo est茅 entrenado, eval煤e y clasifique las caracter铆sticas seg煤n su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificaci贸n para ejecutar una b煤squeda recursiva de eliminaci贸n de caracter铆sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe帽o del modelo hasta identificar las N caracter铆sticas m谩s cr铆ticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de caracter铆sticas, entrene un nuevo modelo y eval煤e su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensi贸n m谩s profunda de los cambios y beneficios:\n",
        "\n",
        "  - 驴El rendimiento del modelo con las caracter铆sticas seleccionadas es similar al del modelo original? 驴C贸mo se comparan en t茅rminos de precisi贸n y robustez? [2 puntos]\n",
        "  - 驴Cu谩les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci贸n del modelo, reducci贸n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci贸n. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es m谩s sencillo de explicar. Explique brevemente por qu茅 la eliminaci贸n de ciertas caracter铆sticas puede facilitar la comprensi贸n y la explicaci贸n del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre n煤mero de festures y desempe帽o. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar m谩s features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwUd_nsuDOe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 3.3 Calibraci贸n Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos m谩s modulares, se recomienda realizar una calibraci贸n del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un m茅todo de calibraci贸n que asegure que las probabilidades generadas incrementen de manera mon贸tona. Una m茅trica ampliamente utilizada para evaluar la precisi贸n de la calibraci贸n de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como despu茅s de la calibraci贸n. Esto le permitir谩 realizar una comparaci贸n cuantitativa y determinar si la calibraci贸n ha mejorado el rendimiento del modelo. Para m谩s informaci贸n sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibraci贸n, examine y comente los resultados obtenidos. A su an谩lisis a帽ada una comparaci贸n visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k-ao0mOU64Ru",
        "Jg_9jBqtgRDO",
        "JdcucZhp-M_0",
        "Qfre1YsSDqla",
        "Bv1HOfcNEPF4",
        "poc9HSNBFeKO",
        "uy5VMU6ae_g6",
        "9bL2m8nNojXM",
        "rD8pQ5Zfq8dE",
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
